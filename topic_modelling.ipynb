{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNWq8f4JAuAqpxAv9ubuzcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PetyoKaratov/NLP-Task/blob/main/topic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcqZIop_mT0V"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds3xMGbzQoGi",
        "outputId": "07d950b7-da6a-4a16-af7d-700227fcba28"
      },
      "source": [
        "!pip install openpyxl==3.0.0\n",
        "!pip install emot\n",
        "!pip install pyldavis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl==3.0.0 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl==3.0.0) (1.4.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl==3.0.0) (1.1.0)\n",
            "Requirement already satisfied: emot in /usr/local/lib/python3.7/dist-packages (3.1)\n",
            "Requirement already satisfied: pyldavis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.0.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.7.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyldavis) (57.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.16.0)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.3.2)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.16)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyldavis) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.21.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyldavis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyldavis) (5.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyldavis) (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iItP_86pxDX",
        "outputId": "21d9d511-28b6-4d2c-b1ab-57a8d000d04f"
      },
      "source": [
        "# imports\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import re                                  # library for regular expression operations\n",
        "import string                              # for string operations\n",
        "import pprint\n",
        "import nltk \n",
        "import numpy as np\n",
        "import tqdm\n",
        "import emot \n",
        "# download the stopwords from NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
        "from nltk.stem import WordNetLemmatizer    # module for lemmatization\n",
        "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models  \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  EPS = np.finfo(np.float).eps\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyF44PFWp91X",
        "outputId": "07585576-3741-40df-ffa2-b2fc65fd2656"
      },
      "source": [
        "# mount the google drive root\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uJUg8VQqljN",
        "outputId": "65314739-f740-46d3-b9ba-01a3a2278035"
      },
      "source": [
        "# read the excel file\n",
        "df = pd.read_excel('./drive/My Drive/NLP_Task_Data.xlsx')\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9915 entries, 0 to 9914\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   Row_id  9915 non-null   int64         \n",
            " 1   Date    9915 non-null   datetime64[ns]\n",
            " 2   Text    9915 non-null   object        \n",
            "dtypes: datetime64[ns](1), int64(1), object(1)\n",
            "memory usage: 232.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sj0-AEUHxXYO",
        "outputId": "bfdd3ec3-47fd-4934-db8b-fb7ff7017c75"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2021-01-18</td>\n",
              "      <td>SelfCare is the BESTCare❗️💯, put yo self first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-01-21</td>\n",
              "      <td>Breaking workaholic thought patterns takes mor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-01-26</td>\n",
              "      <td>Self Care is a must ..... Tarot Reading is hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2021-01-19</td>\n",
              "      <td>Self love and self care. Invest in yourself.  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2021-01-24</td>\n",
              "      <td>So excited for self  care Friday tomorrow!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Row_id       Date                                               Text\n",
              "0       1 2021-01-18  SelfCare is the BESTCare❗️💯, put yo self first...\n",
              "1       2 2021-01-21  Breaking workaholic thought patterns takes mor...\n",
              "2       3 2021-01-26  Self Care is a must ..... Tarot Reading is hap...\n",
              "3       4 2021-01-19  Self love and self care. Invest in yourself.  ...\n",
              "4       5 2021-01-24         So excited for self  care Friday tomorrow!"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4AkKDhnJxSmb",
        "outputId": "4d70efbd-4300-432d-f471-2a41dddcee6d"
      },
      "source": [
        "tweet = df.Text[1]\n",
        "tweet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Breaking workaholic thought patterns takes more than just mindset work, it also takes reading. Here are the self-care books that helped @workbrighterco break their workaholism: https://t.co/Htk8AkXNRR #hustleculture https://t.co/YvdDPhrYuS'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHTVMPiDxiSR"
      },
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_5Qxbx6IquG"
      },
      "source": [
        "To preprocess the tweet we remove stock market tickers, old stype retweet text, hashtafs tokenize the weets with TweetTokenizer and then remove stopwords punctuation and lemmatizing. Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWmX6KV9v-kZ",
        "outputId": "09ff59ba-0736-4970-aab3-966f033b5355"
      },
      "source": [
        "def process_tweet(tweet: str) -> str:\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "    \"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # remove emoticons\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation): # remove punctuation\n",
        "            lemmatize_word = lemmatizer.lemmatize(word, get_wordnet_pos(word))  # lemmatizing word\n",
        "            tweets_clean.append(lemmatize_word)\n",
        "\n",
        "    return tweets_clean\n",
        "\n",
        "# choose the same tweet\n",
        "tweet = df.Text[0]\n",
        "\n",
        "print()\n",
        "print('\\033[92m')\n",
        "print(tweet)\n",
        "print('\\033[94m')\n",
        "\n",
        "# call the imported function\n",
        "tweets_stem = process_tweet(tweet); # Preprocess a given tweet\n",
        "\n",
        "print('preprocessed tweet:')\n",
        "print(tweets_stem) # Print the result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[92m\n",
            "SelfCare is the BESTCare❗️💯, put yo self first for once!\n",
            "\u001b[94m\n",
            "preprocessed tweet:\n",
            "['selfcare', 'bestcare', 'put', 'yo', 'self', 'first']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m14-y6pdLDcH"
      },
      "source": [
        "Apply tweet preprocessing to all tweets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bBByru13nul"
      },
      "source": [
        "df['text_lemmatized'] = df['Text'].apply(process_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Oy7ch1ui39yd",
        "outputId": "570d7638-6c6e-43c0-9a18-bead3a0d3c78"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Text</th>\n",
              "      <th>text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2021-01-18</td>\n",
              "      <td>SelfCare is the BESTCare❗️💯, put yo self first...</td>\n",
              "      <td>[selfcare, bestcare, put, yo, self, first]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-01-21</td>\n",
              "      <td>Breaking workaholic thought patterns takes mor...</td>\n",
              "      <td>[break, workaholic, thought, pattern, take, mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-01-26</td>\n",
              "      <td>Self Care is a must ..... Tarot Reading is hap...</td>\n",
              "      <td>[self, care, must, ..., tarot, reading, happen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2021-01-19</td>\n",
              "      <td>Self love and self care. Invest in yourself.  ...</td>\n",
              "      <td>[self, love, self, care, invest, madewithripl,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2021-01-24</td>\n",
              "      <td>So excited for self  care Friday tomorrow!</td>\n",
              "      <td>[excite, self, care, friday, tomorrow]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Row_id  ...                                    text_lemmatized\n",
              "0       1  ...         [selfcare, bestcare, put, yo, self, first]\n",
              "1       2  ...  [break, workaholic, thought, pattern, take, mi...\n",
              "2       3  ...  [self, care, must, ..., tarot, reading, happen...\n",
              "3       4  ...  [self, love, self, care, invest, madewithripl,...\n",
              "4       5  ...             [excite, self, care, friday, tomorrow]\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z64ghnsyLbC4"
      },
      "source": [
        "Create the Dictionary and Corpus needed for Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyAAVn5G4fxc",
        "outputId": "9b3c8a96-74b9-4e3f-bddf-1758dcf561d1"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(df['text_lemmatized'])\n",
        "\n",
        "# Create Corpus\n",
        "texts = df['text_lemmatized']\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UscGUrYgLj74"
      },
      "source": [
        "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
        "\n",
        "For example, (0, 1) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.\n",
        "\n",
        "This is used as the input by the LDA model.\n",
        "\n",
        "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZicJvxg04o-J",
        "outputId": "15e4a3d5-dcfe-4562-a039-11d427898479"
      },
      "source": [
        "id2word[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'bestcare'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbtwxScyLuJZ",
        "outputId": "176ad690-63c8-4e5f-d2fd-30b44d804ce1"
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('bestcare', 1),\n",
              "  ('first', 1),\n",
              "  ('put', 1),\n",
              "  ('self', 1),\n",
              "  ('selfcare', 1),\n",
              "  ('yo', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qsbt3Z2MI0v"
      },
      "source": [
        "### Base Model\n",
        "\n",
        "We have everything required to train the base Latent Dirichlet Allocation (LDA) model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we’ll use default for the base model).\n",
        "\n",
        "    chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
        "\n",
        "    passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be “epochs”. iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of “passes” and “iterations” high enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf1dHtp3MSum"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=10, \n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OJPPL3lNGxq"
      },
      "source": [
        "### View the topics in LDA model\n",
        "\n",
        "The above LDA model is built with 20 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
        "\n",
        "You can see the keywords for each topic and the weightage(importance) of each keyword using lda_model.print_topics() as shown next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paYUaOqzNQR7",
        "outputId": "dab20155-d985-4663-9694-cac79ce7c1b5"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint.pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.028*\"watch\" + 0.020*\"second\" + 0.019*\"self-care\" + 0.018*\"skincare\" + '\n",
            "  '0.016*\"share\" + 0.016*\"selfcare\" + 0.014*\"favorite\" + 0.013*\"social\" + '\n",
            "  '0.011*\"thats\" + 0.010*\"new\"'),\n",
            " (1,\n",
            "  '0.059*\"selfcare\" + 0.022*\"selflove\" + 0.022*\"mindfulness\" + 0.018*\"love\" + '\n",
            "  '0.018*\"life\" + 0.017*\"inspiration\" + 0.016*\"2021\" + 0.014*\"...\" + '\n",
            "  '0.012*\"happiness\" + 0.012*\"read\"'),\n",
            " (2,\n",
            "  '0.041*\"selfcare\" + 0.027*\"2020\" + 0.021*\"break\" + 0.017*\"rest\" + '\n",
            "  '0.017*\"month\" + 0.015*\"book\" + 0.015*\"still\" + 0.014*\"plan\" + 0.013*\"best\" '\n",
            "  '+ 0.012*\"part\"'),\n",
            " (3,\n",
            "  '0.048*\"self-care\" + 0.027*\"time\" + 0.024*\"help\" + 0.021*\"selfcare\" + '\n",
            "  '0.019*\"day\" + 0.017*\"take\" + 0.017*\"health\" + 0.016*\"make\" + 0.016*\"tip\" + '\n",
            "  '0.013*\"mental\"'),\n",
            " (4,\n",
            "  '0.032*\"therapy\" + 0.024*\"bliss\" + 0.024*\"self\" + 0.024*\"care\" + '\n",
            "  '0.022*\"call\" + 0.022*\"soul\" + 0.022*\"music\" + 0.022*\"soundhound\" + '\n",
            "  '0.020*\"season\" + 0.014*\"christmas\"'),\n",
            " (5,\n",
            "  '0.025*\"holiday\" + 0.021*\"self-care\" + 0.019*\"mask\" + 0.016*\"calm\" + '\n",
            "  '0.016*\"breathing\" + 0.015*\"enjoy\" + 0.015*\"breathe\" + 0.012*\"practice\" + '\n",
            "  '0.012*\"routine\" + 0.012*\"face\"'),\n",
            " (6,\n",
            "  '0.023*\"self-care\" + 0.015*\"join\" + 0.015*\"exercise\" + 0.014*\"u\" + 0.011*\"2\" '\n",
            "  '+ 0.011*\"use\" + 0.011*\"work\" + 0.010*\"new\" + 0.008*\"video\" + 0.008*\"year\"'),\n",
            " (7,\n",
            "  '0.073*\"selfcare\" + 0.028*\"selflove\" + 0.025*\"covid\" + 0.023*\"mentalhealth\" '\n",
            "  '+ 0.021*\"19\" + 0.016*\"quarantine\" + 0.015*\"wellness\" + 0.015*\"love\" + '\n",
            "  '0.014*\"beauty\" + 0.013*\"health\"'),\n",
            " (8,\n",
            "  '0.176*\"care\" + 0.161*\"self\" + 0.030*\"day\" + 0.020*\"im\" + 0.015*\"need\" + '\n",
            "  '0.015*\"today\" + 0.013*\"...\" + 0.013*\"take\" + 0.012*\"get\" + 0.011*\"go\"'),\n",
            " (9,\n",
            "  '0.034*\"self-care\" + 0.022*\"selfcare\" + 0.021*\"time\" + 0.018*\"practice\" + '\n",
            "  '0.016*\"take\" + 0.016*\"home\" + 0.015*\"good\" + 0.014*\"...\" + 0.013*\"today\" + '\n",
            "  '0.013*\"morning\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcJz1cJPOpJc"
      },
      "source": [
        "### Compute Model Perplexity and Coherence Score\n",
        "\n",
        "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON82K4qJOK-X",
        "outputId": "8e922c28-e0e7-4759-82bf-96d47c60dbee"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['text_lemmatized'], dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Perplexity:  -8.637500543373694\n",
            "\n",
            "Coherence Score:  0.38615394180736784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjCCrKGh2tD"
      },
      "source": [
        "### Hyperparameter Tuning\n",
        "\n",
        "First, let’s differentiate between model hyperparameters and model parameters :\n",
        "\n",
        "    Model hyperparameters can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
        "\n",
        "    Model parameters can be thought of as what the model learns during training, such as the weights for each word in a given topic\n",
        "\n",
        "Now that we have the baseline coherence score for the default LDA model, let’s perform a series of sensitivity tests to help determine the following model hyperparameters:\n",
        "\n",
        "    Number of Topics (K)\n",
        "    Dirichlet hyperparameter alpha: Document-Topic Density\n",
        "    Dirichlet hyperparameter beta: Word-Topic Density\n",
        "\n",
        "We’ll perform these tests in sequence, one parameter at a time by keeping others constant. We’ll use C_v as our choice of metric for performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCzEqRcYh42f"
      },
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    \n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df['text_lemmatized'], dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwUWXSLZiJv0"
      },
      "source": [
        "Let’s call the function, and iterate it over the range of topics, alpha, and beta parameter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wkgVh-l_4mh"
      },
      "source": [
        "grid = {}\n",
        "grid['Validation_Set'] = {}# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 11\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [\n",
        "               corpus]\n",
        "corpus_title = ['100% Corpus']\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }# Can take a long time to run\n",
        "\n",
        "pbar = tqdm.tqdm(total=270)\n",
        "\n",
        "# iterate through validation corpuses\n",
        "for i in range(len(corpus_sets)):\n",
        "    # iterate through number of topics\n",
        "    for k in topics_range:\n",
        "        # iterate through alpha values\n",
        "        for a in alpha:\n",
        "            # iterare through beta values\n",
        "            for b in beta:\n",
        "                # get the coherence score for the given parameters\n",
        "                cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, k=int(k), a=a, b=b)\n",
        "                # Save the model results\n",
        "                model_results['Validation_Set'].append(corpus_title[i])\n",
        "                model_results['Topics'].append(k)\n",
        "                model_results['Alpha'].append(a)\n",
        "                model_results['Beta'].append(b)\n",
        "                model_results['Coherence'].append(cv)\n",
        "                \n",
        "                pbar.update(1)\n",
        "pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
        "pbar.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uui3QWjE-t_p"
      },
      "source": [
        "## Final Model\n",
        "\n",
        "Let’s train the final model using the above selected parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "RgoxfHyBdvAg",
        "outputId": "782f794a-421b-4c82-eb16-633902e4aa00"
      },
      "source": [
        "model_df = pd.read_csv('./drive/My Drive/lda_tuning_results.csv')\n",
        "model_df.sort_values(by=['Coherence']).tail(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Validation_Set</th>\n",
              "      <th>Topics</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Beta</th>\n",
              "      <th>Coherence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>6</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.510706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>8</td>\n",
              "      <td>symmetric</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.512474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>7</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.515802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>8</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.516026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>7</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.520930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>6</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.522290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>9</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.528819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>8</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.541064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>2</td>\n",
              "      <td>asymmetric</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.542925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>100% Corpus</td>\n",
              "      <td>5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.9099999999999999</td>\n",
              "      <td>0.558495</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Validation_Set  Topics       Alpha                Beta  Coherence\n",
              "143    100% Corpus       6   symmetric  0.9099999999999999   0.510706\n",
              "203    100% Corpus       8   symmetric  0.9099999999999999   0.512474\n",
              "153    100% Corpus       7        0.01  0.9099999999999999   0.515802\n",
              "182    100% Corpus       8        0.01                0.61   0.516026\n",
              "177    100% Corpus       7  asymmetric                0.61   0.520930\n",
              "122    100% Corpus       6        0.01                0.61   0.522290\n",
              "223    100% Corpus       9        0.61  0.9099999999999999   0.528819\n",
              "188    100% Corpus       8        0.31  0.9099999999999999   0.541064\n",
              "28     100% Corpus       2  asymmetric  0.9099999999999999   0.542925\n",
              "93     100% Corpus       5        0.01  0.9099999999999999   0.558495"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx9QpU0GBDES"
      },
      "source": [
        "The best model is with 5 topis but I select the one with 8 to work with more topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MTqMbn1vsD0"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=8, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=0.31,\n",
        "                                           eta=0.90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "mxfkG_87-mV_",
        "outputId": "d0070f1b-61a7-4de6-b5b2-43cb45e05830"
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "LDAvis_prepared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1711396578480356644559357520\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1711396578480356644559357520_data = {\"mdsDat\": {\"x\": [-0.20196445116677192, -0.17551173986858876, 0.060755861097262887, 0.06386165619581148, 0.06606120326753681, 0.060870536725398425, 0.05983481409047815, 0.06609211965887302], \"y\": [-0.13012812138161622, 0.14418109055682157, 0.03339035769163963, -0.008457787807906422, -0.009190101357823657, -0.011237801243091735, -0.008527875577852896, -0.010029760880170211], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [35.82970080038836, 34.74141499974821, 11.14713220907545, 5.6700825271885895, 3.9818834171314745, 3.1747990155332815, 2.921384854145988, 2.533602176788648]}, \"tinfo\": {\"Term\": [\"care\", \"self\", \"self-care\", \"selfcare\", \"day\", \"make\", \"selflove\", \"love\", \"help\", \"health\", \"mentalhealth\", \"therapy\", \"im\", \"like\", \"go\", \"time\", \"bliss\", \"motivation\", \"tip\", \"heal\", \"inspiration\", \"soul\", \"call\", \"soundhound\", \"sure\", \"skincare\", \"u\", \"stress\", \"season\", \"beauty\", \"self\", \"care\", \"day\", \"im\", \"watch\", \"mask\", \"dont\", \"go\", \"like\", \"sunday\", \"really\", \"ive\", \"form\", \"thats\", \"lol\", \"i'm\", \"night\", \"bath\", \"almost\", \"sometimes\", \"do\", \"bed\", \"..\", \"glass\", \"play\", \"water\", \"shower\", \"yall\", \"gonna\", \"nail\", \"hair\", \"hour\", \"say\", \"morning\", \"eat\", \"lot\", \"always\", \"every\", \"...\", \"today\", \"get\", \"need\", \"take\", \"work\", \"little\", \"love\", \"feel\", \"put\", \"well\", \"time\", \"good\", \"call\", \"selfcare\", \"thing\", \"new\", \"self-care\", \"help\", \"health\", \"tip\", \"u\", \"mental\", \"covid\", \"join\", \"learn\", \"check\", \"19\", \"exercise\", \"share\", \"breathing\", \"holiday\", \"yoga\", \"calm\", \"resource\", \"healthy\", \"guide\", \"breathe\", \"support\", \"stress\", \"may\", \"find\", \"team\", \"pandemic\", \"simple\", \"physical\", \"teacher\", \"wellness\", \"series\", \"practice\", \"selfcare\", \"time\", \"life\", \"great\", \"way\", \"2020\", \"new\", \"mentalhealth\", \"take\", \"2021\", \"year\", \"need\", \"thing\", \"get\", \"today\", \"selflove\", \"therapy\", \"bliss\", \"soundhound\", \"motivation\", \"inspiration\", \"soul\", \"loveyourself\", \"happiness\", \"positivevibes\", \"quote\", \"without\", \"mindset\", \"mentalhealthawareness\", \"dailyinspiration\", \"livelyrics\", \"quoteoftheday\", \"season\", \"heal\", \"mentalhealthmatters\", \"inspirationalquotes\", \"positivity\", \"blackblogger\", \"therapymemes\", \"ebonyinsights\", \"empathhealer\", \"femaleblogger\", \"selfhealer\", \"personaldevelopment\", \"growth\", \"peace\", \"music\", \"christmas\", \"selfcare\", \"love\", \"mentalhealth\", \"success\", \"mindfulness\", \"spiritual\", \"call\", \"chakrahealing\", \"meditation\", \"life\", \"skincare\", \"beauty\", \"skin\", \"product\", \"natural\", \"vitamin\", \"shop\", \"cbd\", \"glow\", \"soap\", \"bio\", \"weight\", \"organic\", \"vegan\", \"hydrate\", \"scrub\", \"transformation\", \"treatyourself\", \"butter\", \"lip\", \"weightloss\", \"healthylifestyle\", \"betteryou\", \"sample\", \"sale\", \"mineral\", \"makeup\", \"moisturize\", \"allnatural\", \"skincareroutine\", \"101\", \"oil\", \"fitness\", \"tea\", \"click\", \"beautiful\", \"luxury\", \"selfcare\", \"body\", \"link\", \"challenge\", \"make\", \"sure\", \"saturday\", \"priority\", \"selfcaresunday\", \"could\", \"lovely\", \"park\", \"slime\", \"audition\", \"cast\", \"film\", \"actress\", \"broadway\", \"femaledirector\", \"imdb\", \"mini-cookie\", \"offbroadway\", \"playbill\", \"theatre\", \"bts\", \"mm\", \"10:00\", \"north\", \"qcr\", \"timely\", \"dnr\", \"marismith\", \"mothernaturenet\", \"holler\", \"soldier\", \"sketch\", \"storm\", \"resilence\", \"selfnurture\", \"happynewyear\", \"selfish\", \"sponsor\", \"eve\", \"book\", \"massage\", \"appointment\", \"spaday\", \"doctor\", \"blackownedbusiness\", \"chiropractic\", \"lake\", \"neckpain\", \"therapeutic\", \"dentist\", \"massagetherapy\", \"microblading\", \"sweet\", \"salon\", \"alternativemedicine\", \"brookiegirl\", \"brookiegirlannapolis\", \"brookiegirlmontgomery\", \"brookiegirlnationalharbor\", \"brookiegirltysons\", \"buyblack\", \"bodybutter\", \"coloradolife\", \"naturalmedicine\", \"thrivechiropracticstudio\", \"visitdurango\", \"frontier\", \"nasa\", \"outfitoftheday\", \"press\", \"reschedule\", \"halsey\", \"recommendation\", \"jax\", \"breaker\", \"damper\", \"shun\", \"reflexology\", \"lady\", \"takedown\", \"spa\", \"final\", \"lawn\", \"saturdaymorning\", \"newtonstyleme\", \"opening\", \"scent\", \"relaxation\", \"fall\", \"reputationintelligence\", \"clarity\", \"mediation\", \"eliminatebullying\", \"divorcemediation\", \"cdcdivorcecoach\", \"divorcecoach\", \"maritalmediation\", \"supremecourtmediator\", \"nadpdivorceprofessional\", \"mirror\", \"divorce\", \"crismuss\", \"erbahdee\", \"giftfromafriend\", \"marr\", \"mha\", \"mhfa\", \"musicislife\", \"selfcareishealthy\", \"alexia\", \"georghiou\", \"guitar\", \"thinkbigsundaywithmarsha\", \"character\", \"sundaymotivation\", \"theyre\", \"google\", \"wellnessmatters\", \"innovation\", \"reflexology\", \"merrychristmas\", \"youmatter\", \"sock\", \"hit\", \"harmony\", \"akafit\", \"mylifestyle\", \"6miles\", \"allyouhaveistime\", \"enjoythescenery\", \"pastorlife\", \"payattentiontothehiddengems\", \"stoprushingeverywhere\", \"justdoit\", \"takeyourtime\", \"slowdown\", \"neighborhood\", \"athlete\", \"israel\", \"quinn\", \"emdr\", \"gary\", \"autoimmunedisease\", \"chronicillness\", \"guthealthy\", \"ibsdiet\", \"digestivehealth\", \"microbiome\", \".\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\", \"atlyoga\", \"iamstephf_yoga\", \"igyogafam\", \"shelbyadina\", \"springbloomsyogachallenge\", \"saam\", \"warriortwopose\", \"yoga.denisse\", \"yogasequence\", \"fitnessmotivation\", \"annie\", \"va\", \"staystrong\", \"handbook\", \"psychologist\", \"phrase\"], \"Freq\": [3379.0, 3109.0, 1620.0, 1884.0, 964.0, 220.0, 325.0, 450.0, 400.0, 395.0, 348.0, 156.0, 365.0, 375.0, 365.0, 837.0, 122.0, 120.0, 275.0, 124.0, 112.0, 111.0, 222.0, 109.0, 70.0, 79.0, 252.0, 266.0, 103.0, 71.0, 3106.6385198975645, 3376.8442053647395, 959.8445369956472, 362.6339572648994, 221.61327336358323, 173.09016573460968, 224.04240773633117, 359.8279164431193, 369.7708245666375, 223.06571286892725, 147.38404916213008, 116.00913836516176, 173.58243791439668, 89.21082491861763, 83.93601523966709, 124.12545875863579, 101.22624427166048, 93.64334047943149, 103.23271619726836, 83.64063448847895, 58.97469555132864, 56.99368541594737, 63.34331951649999, 56.7055218367267, 60.24133103576396, 55.12940377037829, 52.58384071481077, 57.07287807028525, 46.409898962961634, 48.788180618727324, 88.54071268185282, 67.8394541211449, 147.62280454896924, 123.46676644277117, 94.8727344843489, 92.41087209008082, 80.29507735591339, 150.43573548054303, 387.2425294967735, 406.5693310764325, 392.0881082299278, 356.7489095311256, 384.8834518416433, 224.4158037180317, 134.0071190390826, 263.2425317879891, 190.7964069495435, 145.23937166396698, 149.86059664799964, 274.90892674231225, 159.11744825378258, 141.31042828104324, 262.29900102500363, 143.68723270599082, 150.3729613473275, 1616.8462643539074, 397.6128081621031, 392.190637539629, 273.0362256141504, 249.7503806166514, 214.84946753305454, 207.50495131303893, 165.04252186410864, 187.54078995071728, 151.77814485006266, 168.37037892508812, 149.73773248405593, 121.9651388661859, 129.57440414307428, 212.6065477730565, 133.02840416654777, 131.0113007113178, 89.97556687874913, 108.15519591781356, 111.94676816656853, 116.53650940267569, 81.84262278760846, 258.6727779595726, 89.45767565118632, 130.72364443918275, 75.1633989071155, 74.71423989627405, 80.4937398207833, 63.26101281878956, 70.23879160498257, 251.895011826807, 77.32827874248333, 281.89633901045175, 1131.6003661350467, 560.2580534792919, 232.4586572286961, 178.31925630069344, 192.09301493995514, 141.14710392332483, 281.0681697107256, 235.49391082015117, 283.176944310743, 177.1063049817951, 188.6719010939994, 175.17176052573367, 148.42886050466393, 161.96616847895737, 161.05192005884336, 322.5744016606053, 153.6261362254431, 119.89690856664153, 106.7161931476414, 117.34885978222376, 109.18890347883585, 108.31522570051862, 92.05867174250076, 77.94140831427457, 56.302767786030756, 60.71054893386288, 49.47464216236682, 64.76992534933864, 35.859122928579325, 32.670500567907446, 30.39050838787885, 37.342546298216995, 95.46908329173166, 114.59551269523526, 39.90225605878197, 31.830354031647023, 29.271142864303, 31.69484521284736, 31.687953094310092, 31.68516504242149, 31.68516504242149, 31.68516504242149, 31.68516504242149, 30.135561054231086, 55.980730833944435, 71.48864198301408, 84.89222517998996, 77.73532989986153, 444.62513797163035, 172.82669660470972, 111.14353136018114, 33.37408343848578, 69.03993874581903, 41.489393601959286, 79.33144551280662, 33.056387978391435, 38.92130951035666, 34.47604229260629, 75.89402840303072, 67.3787453289304, 49.726477273882765, 43.16555811745485, 19.802413071998238, 18.049359720934444, 16.380633765869202, 13.746537863848447, 15.136065399773226, 12.558613326579847, 14.120323816963717, 9.953957309278584, 9.22072492495651, 8.56686843234648, 11.560629873951873, 13.076048975045365, 9.21584846960257, 9.419355295777967, 8.527455665909864, 9.830069636872512, 11.575032367953181, 17.915211910552117, 7.236736519443145, 7.931605959753112, 7.829755069316219, 6.726509019029551, 10.337462530476792, 10.243263180635946, 6.039176389338261, 6.010964460429195, 9.235112754223868, 11.314538385649705, 25.341215799505616, 18.12479166184546, 15.274495312468831, 22.63408865978453, 10.925381203461047, 45.074516568293696, 11.871909555185571, 10.996732897808444, 9.507267787911488, 209.1375275305372, 64.40545663358326, 41.269451675283925, 20.361265919847796, 8.905500572847929, 16.86059271830852, 6.991572534840302, 3.601292430808633, 5.068338906773936, 2.4706303743879703, 2.3946602665234766, 2.400152085199182, 2.388863582396494, 2.388863582396494, 2.388863582396494, 2.388863582396494, 2.388863582396494, 2.388863582396494, 2.388863582396494, 2.388863582396494, 2.390814085201756, 2.2749029684605357, 2.9987507796074873, 1.7994226644947962, 2.7904645224395557, 1.4234169434592443, 1.5640650216260643, 1.6585677079343129, 1.6585677079343129, 1.8624101687428998, 1.8624101687428998, 3.4916178040913186, 6.651170040140262, 5.119143151594342, 5.119143151594342, 2.7487371807273546, 5.885129940964458, 4.3040431892512885, 2.487437805114143, 37.870529535849535, 11.66148900886938, 6.471776433418919, 5.098254024945779, 5.1102369097137545, 3.3612489269893957, 1.5808564062050956, 2.0588671989251126, 1.4304912229471678, 2.167028081457552, 1.3201998029198052, 1.641909515636518, 1.003265928361203, 1.633172669688453, 2.5920338447754268, 0.9990791758508473, 0.9459798396144534, 0.9459798396144534, 0.9459798396144534, 0.9459798396144534, 0.9459798396144534, 0.9459798396144534, 0.9440211917207559, 0.9858747096632726, 0.9858747096632726, 0.9858747096632726, 0.9858747096632726, 0.8617632328708521, 0.8617632328708521, 0.8617632328708521, 1.899528617749467, 2.410214856891138, 1.3748913669621419, 3.1459890496331058, 1.3748913669621419, 1.726944333787147, 1.3771322712259586, 1.3771322712259586, 2.030818100442871, 1.6759931647483661, 1.256632770335651, 2.8130006742449023, 1.7435337632668566, 1.2293395755440815, 1.2291846515129101, 1.209082564147953, 1.4544332044596284, 1.3317106705109707, 1.2886876753729015, 4.214226544586366, 2.351295974983136, 3.134162914758002, 2.1455439075017253, 2.0504634470561776, 1.950113788406508, 1.9309719164606427, 1.9309719164606427, 1.9309719164606427, 1.9309719164606427, 1.9103040192915604, 2.1381688967134758, 4.7004416922030785, 1.83579323216936, 1.83579323216936, 1.83579323216936, 1.83579323216936, 1.83579323216936, 1.83579323216936, 1.83579323216936, 1.9147436482284226, 1.639554766379887, 1.639554766379887, 1.8321162825052633, 1.3765784197220479, 1.9681354196140248, 1.4461745700561226, 3.271348293365445, 1.6583804108767006, 1.1780579162134521, 1.897054911412107, 2.03401339738042, 1.891535264623951, 2.353008892184324, 1.767940777322976, 1.6967569340797304, 10.817446319073067, 10.638290431034575, 10.638290431034575, 10.404458443238163, 10.404458443238163, 10.404458443238163, 10.404458443238163, 10.404458443238163, 10.404458443238163, 10.351423613239204, 10.231647924568396, 10.166678619633556, 10.193363707800051, 3.6966976368277904, 2.8167949182738368, 2.8167949182738368, 2.813265301744289, 2.8163331425173226, 1.4974911746134927, 1.4475360381459255, 1.4309552819337354, 1.4309552819337354, 1.427317352392852, 1.427317352392852, 1.6130763832033816, 1.6130763832033816, 1.6130763832033816, 1.6130763832033816, 1.6130763832033816, 1.6130763832033816, 2.1921842328886125, 1.6130763832033816, 1.6130763832033816, 1.6130763832033816, 6.4656176259078215, 2.2838991425122934, 2.2838991425122934, 1.807161157667302, 5.250679443230747, 1.7368675551325237, 1.771893130627439], \"Total\": [3379.0, 3109.0, 1620.0, 1884.0, 964.0, 220.0, 325.0, 450.0, 400.0, 395.0, 348.0, 156.0, 365.0, 375.0, 365.0, 837.0, 122.0, 120.0, 275.0, 124.0, 112.0, 111.0, 222.0, 109.0, 70.0, 79.0, 252.0, 266.0, 103.0, 71.0, 3109.311396119629, 3379.7866626204363, 964.8432458447779, 365.1298151177807, 224.64927953592291, 175.82729235111267, 227.69106435589612, 365.71245066289913, 375.8866298056792, 226.84893636109496, 150.32600830272767, 118.52792943592961, 177.39504979315302, 91.7330721944786, 86.37322055347876, 127.99578687321728, 104.42479986036979, 96.67956654105981, 107.21210374000852, 86.87973788172675, 61.521176001119564, 59.46380948826653, 66.11848649431899, 59.37402974968545, 63.24552157259024, 57.89268086548401, 55.225486217423054, 59.96711711766815, 48.81045540209847, 51.32018096534405, 93.17997351478868, 71.4460522283764, 156.92308036801532, 133.15934735908723, 101.55202822851729, 101.18067594946943, 86.71797402701476, 178.58033290460418, 531.0202719011116, 570.0644705113866, 556.2452029168093, 534.2475580220616, 669.9177375852784, 334.26216425956056, 167.55627391548714, 450.9863527106216, 319.99826050904636, 207.2367154279767, 228.7082052948978, 837.5508369628453, 273.68087063408996, 222.7515534244175, 1884.7520919023266, 293.96144150456513, 433.986017805218, 1620.3573399974307, 400.79411251442315, 395.5152953129216, 275.76783519508973, 252.84272657591004, 217.67608975037106, 210.74883220564985, 167.62783446650636, 190.73045432758045, 154.56809486897515, 171.51631718453234, 153.48746994961056, 125.02107738378129, 132.84215423042528, 218.14083762486288, 136.57952222436526, 134.54345531889112, 92.41095626460877, 111.42165759225848, 115.41024626928808, 120.15104615430259, 84.4242546594312, 266.93896705563577, 92.38483422096589, 135.02307208056743, 77.88894165958028, 77.42904496156955, 83.48134150830077, 65.86597995247291, 73.1938980248626, 263.87905328331766, 80.59814066285375, 343.8180953812448, 1884.7520919023266, 837.5508369628453, 301.5900190684316, 220.21049538326835, 243.20465924829966, 166.93224913605277, 433.986017805218, 348.7666215697327, 669.9177375852784, 282.91652191388283, 342.37207079885644, 534.2475580220616, 293.96144150456513, 556.2452029168093, 570.0644705113866, 325.9805592645124, 156.3034712018936, 122.48717070430324, 109.27589491187233, 120.25236444482593, 112.29773113508544, 111.51822751060244, 94.82912555976183, 81.03694407558594, 58.99601554533705, 63.64247034051095, 52.324487521440844, 69.47061008500764, 38.69793116687931, 35.348125883463105, 32.964197881280946, 40.54890165637035, 103.83196030883346, 124.84426201125338, 43.53766396365415, 34.82168581340037, 32.02389380511187, 34.751566454154364, 34.747901909154706, 34.746490611738786, 34.746490611738786, 34.746490611738786, 34.746490611738786, 33.25308032259116, 62.203702915463616, 79.90742815791127, 112.2593240131215, 123.33519006129498, 1884.7520919023266, 450.9863527106216, 348.7666215697327, 38.280318530433526, 153.31588274651335, 59.0005127767657, 222.7515534244175, 38.159038057778055, 116.2409592968357, 301.5900190684316, 79.43517616629335, 71.56341904651823, 53.08411688873185, 46.117157545252354, 22.44806539348674, 20.768654945921085, 19.407205029693795, 16.494330038802737, 18.37511765850421, 15.59009371322134, 17.70152069832873, 12.885649606761936, 12.048947722468975, 11.240049185861766, 15.17979120527283, 17.219449293952003, 12.199658346014317, 12.498701201525666, 11.342911783891566, 13.093678603676308, 15.440618938097403, 24.19158502015039, 9.829179785471668, 10.932116220583046, 10.858599933814514, 9.346508204737335, 14.392300705883402, 14.271006978879361, 8.682571919759033, 8.652890072361103, 14.849989042079523, 23.24671907174013, 84.20284797113241, 50.13060824614293, 40.599581143641174, 104.0533417495987, 24.012461398064566, 1884.7520919023266, 139.757677518064, 77.88589831770199, 99.19718767016504, 220.8839588237913, 70.91165283946825, 51.41238267798265, 25.99029413509913, 12.462970254684988, 27.16754319081291, 11.439994044170817, 6.552296708899585, 11.285396230973179, 5.9230664907125945, 5.873741765127698, 5.898229042327871, 5.873195210868093, 5.873195210868093, 5.873195210868093, 5.873195210868093, 5.873195210868093, 5.873195210868093, 5.873195210868093, 5.873195210868093, 5.986569628828168, 6.124933900912785, 8.0902692977086, 4.858548198089534, 8.050919518144283, 4.4826557459227825, 5.345530755209001, 5.678717668789097, 5.678717668789097, 6.453026719868306, 6.453026719868306, 14.620972068413872, 41.44232591886415, 35.843523616163054, 35.843523616163054, 13.46498351556342, 66.6385669204446, 39.639696986829506, 18.206091439075546, 42.92093413178162, 15.49700270861091, 9.763252639729389, 8.822218283669425, 8.94922813508652, 6.818955563368503, 4.359777383026782, 6.1845812595826475, 4.466667232062649, 7.340318166672985, 4.685333168480351, 6.200070348733295, 3.836907010023998, 6.52108377693009, 10.722177623983603, 4.250326188972551, 4.053237271043849, 4.053237271043849, 4.053237271043849, 4.053237271043849, 4.053237271043849, 4.053237271043849, 4.076672768010567, 4.260944380848029, 4.260944380848029, 4.260944380848029, 4.260944380848029, 3.750231747463804, 3.750231747463804, 3.750231747463804, 8.291174369179526, 11.049648848297268, 6.212610066974595, 15.404195422762237, 6.212610066974595, 8.581357321095322, 6.835976888557466, 6.835976888557466, 13.544269424194434, 11.419719116456527, 6.8887794993644995, 39.75515363144105, 15.561978553023476, 7.096048013559379, 7.114637928389006, 7.030164421958676, 13.183368017765002, 16.70894428214336, 46.312404803912614, 7.500293351136893, 5.172921096527166, 7.169320907261281, 4.966382764965664, 4.917321527643464, 4.783454920596064, 4.784284059448077, 4.784284059448077, 4.784284059448077, 4.784284059448077, 4.781265547726856, 5.839265811618139, 13.086936841951323, 5.17030790364524, 5.17030790364524, 5.17030790364524, 5.17030790364524, 5.17030790364524, 5.17030790364524, 5.17030790364524, 5.417529875461027, 4.642087825941065, 4.642087825941065, 5.192034660658854, 4.209001279466344, 6.1837834692528615, 4.58614265651736, 10.467066719831909, 5.3809674309107525, 4.18521141434713, 7.201124335651456, 13.544269424194434, 11.762878843875626, 31.953522007851316, 17.86436130846046, 18.318220017200847, 19.077395671929665, 19.35030840994014, 19.35030840994014, 19.729597631501928, 19.729597631501928, 19.729597631501928, 19.729597631501928, 19.729597631501928, 19.729597631501928, 19.968030432089243, 20.03251693663627, 20.238496940123035, 20.43624764559212, 8.380723997179054, 6.935732383758719, 6.935732383758719, 6.946346734567324, 6.976738288134603, 4.494009203390702, 4.506894363642585, 4.507360134587163, 4.507360134587163, 4.513341268884043, 4.513341268884043, 5.186561755986342, 5.186561755986342, 5.186561755986342, 5.186561755986342, 5.186561755986342, 5.186561755986342, 7.3767681337258555, 5.186561755986342, 5.186561755986342, 5.186561755986342, 30.182815651890618, 8.083995936241053, 8.083995936241053, 6.1126194957083415, 35.70991410806298, 7.800203190269647, 11.067745761943332], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.7129, -2.6295, -3.8874, -4.8608, -5.3532, -5.6003, -5.3423, -4.8685, -4.8413, -5.3467, -5.7611, -6.0005, -5.5975, -6.2631, -6.3241, -5.9329, -6.1368, -6.2147, -6.1172, -6.3276, -6.677, -6.7112, -6.6056, -6.7163, -6.6558, -6.7445, -6.7917, -6.7098, -6.9166, -6.8667, -6.2707, -6.537, -5.7595, -5.9382, -6.2016, -6.2279, -6.3684, -5.7406, -4.7951, -4.7464, -4.7827, -4.8771, -4.8012, -5.3407, -5.8563, -5.1811, -5.5029, -5.7758, -5.7444, -5.1377, -5.6845, -5.8032, -5.1847, -5.7865, -5.741, -3.3351, -4.7378, -4.7516, -5.1137, -5.2028, -5.3534, -5.3882, -5.6171, -5.4893, -5.7009, -5.5971, -5.7144, -5.9196, -5.8591, -5.3639, -5.8327, -5.848, -6.2238, -6.0397, -6.0053, -5.9651, -6.3185, -5.1677, -6.2295, -5.8502, -6.4036, -6.4096, -6.3351, -6.576, -6.4714, -5.1943, -6.3752, -5.0818, -3.6919, -4.3949, -5.2746, -5.5397, -5.4653, -5.7735, -5.0847, -5.2616, -5.0772, -5.5466, -5.4833, -5.5575, -5.7232, -5.6359, -5.6416, -3.8102, -4.552, -4.7999, -4.9164, -4.8214, -4.8935, -4.9015, -5.0641, -5.2306, -5.5558, -5.4804, -5.6851, -5.4157, -6.007, -6.1001, -6.1724, -5.9664, -5.0278, -4.8451, -5.9001, -6.1261, -6.21, -6.1304, -6.1306, -6.1307, -6.1307, -6.1307, -6.1307, -6.1809, -5.5615, -5.317, -5.1452, -5.2332, -3.4893, -4.4343, -4.8757, -6.0788, -5.3519, -5.8611, -5.2129, -6.0883, -5.925, -6.0463, -4.5812, -4.7002, -5.004, -5.1455, -5.9248, -6.0175, -6.1145, -6.2898, -6.1935, -6.3802, -6.263, -6.6126, -6.6891, -6.7627, -6.463, -6.3398, -6.6897, -6.6678, -6.7673, -6.6251, -6.4617, -6.0249, -6.9314, -6.8397, -6.8526, -7.0045, -6.5748, -6.584, -7.1123, -7.117, -6.6876, -6.4845, -5.6781, -6.0133, -6.1844, -5.7911, -6.5195, -5.1023, -6.4364, -6.513, -6.6585, -3.2141, -4.3919, -4.837, -5.5435, -6.3705, -5.7322, -6.6124, -7.2758, -6.9341, -7.6527, -7.6839, -7.6816, -7.6863, -7.6863, -7.6863, -7.6863, -7.6863, -7.6863, -7.6863, -7.6863, -7.6855, -7.7352, -7.4589, -7.9697, -7.5309, -8.2041, -8.1098, -8.0512, -8.0512, -7.9353, -7.9353, -7.3068, -6.6623, -6.9241, -6.9241, -7.546, -6.7847, -7.0976, -7.6459, -4.6964, -5.8743, -6.4632, -6.7017, -6.6994, -7.1183, -7.8727, -7.6085, -7.9726, -7.5573, -8.0528, -7.8348, -8.3274, -7.8401, -7.3782, -8.3315, -8.3862, -8.3862, -8.3862, -8.3862, -8.3862, -8.3862, -8.3882, -8.3448, -8.3448, -8.3448, -8.3448, -8.4794, -8.4794, -8.4794, -7.689, -7.4509, -8.0122, -7.1845, -8.0122, -7.7843, -8.0106, -8.0106, -7.6222, -7.8142, -8.1022, -7.2964, -7.7747, -8.1241, -8.1243, -8.1408, -7.956, -8.0442, -8.077, -6.809, -7.3925, -7.1051, -7.484, -7.5294, -7.5795, -7.5894, -7.5894, -7.5894, -7.5894, -7.6002, -7.4875, -6.6998, -7.64, -7.64, -7.64, -7.64, -7.64, -7.64, -7.64, -7.5978, -7.753, -7.753, -7.642, -7.9278, -7.5703, -7.8785, -7.0622, -7.7416, -8.0836, -7.6071, -7.5374, -7.61, -7.3917, -7.6776, -7.7187, -5.7239, -5.7406, -5.7406, -5.7628, -5.7628, -5.7628, -5.7628, -5.7628, -5.7628, -5.7679, -5.7795, -5.7859, -5.7833, -6.7976, -7.0694, -7.0694, -7.0707, -7.0696, -7.7012, -7.7352, -7.7467, -7.7467, -7.7492, -7.7492, -7.6269, -7.6269, -7.6269, -7.6269, -7.6269, -7.6269, -7.3201, -7.6269, -7.6269, -7.6269, -6.2385, -7.2791, -7.2791, -7.5133, -6.4467, -7.5529, -7.533], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0255, 1.0255, 1.0212, 1.0195, 1.0128, 1.0107, 1.0102, 1.0102, 1.01, 1.0096, 1.0066, 1.0049, 1.0047, 0.9985, 0.9978, 0.9957, 0.9953, 0.9945, 0.9886, 0.9884, 0.9841, 0.984, 0.9835, 0.9804, 0.9777, 0.9775, 0.9774, 0.9769, 0.976, 0.9758, 0.9753, 0.9746, 0.9653, 0.9508, 0.9584, 0.9357, 0.9494, 0.8549, 0.7106, 0.6884, 0.6767, 0.6226, 0.4722, 0.628, 0.803, 0.488, 0.5093, 0.6709, 0.6037, -0.0876, 0.4841, 0.5713, -0.9457, 0.3106, -0.0335, 1.0551, 1.0493, 1.0488, 1.0473, 1.0449, 1.0442, 1.0417, 1.0417, 1.0404, 1.039, 1.0387, 1.0325, 1.0325, 1.0323, 1.0315, 1.0309, 1.0306, 1.0305, 1.0275, 1.0268, 1.0267, 1.0262, 1.0258, 1.025, 1.0249, 1.0216, 1.0215, 1.0208, 1.0169, 1.016, 1.0108, 1.0158, 0.8587, 0.5471, 0.6552, 0.7969, 0.8462, 0.8213, 0.8895, 0.6228, 0.6645, 0.1962, 0.5888, 0.4613, -0.0579, 0.3739, -0.1766, -0.2068, 2.1835, 2.1767, 2.1726, 2.1703, 2.1695, 2.1659, 2.1648, 2.1643, 2.155, 2.1473, 2.1468, 2.138, 2.1239, 2.1178, 2.1152, 2.1127, 2.1116, 2.11, 2.1083, 2.1068, 2.1042, 2.1041, 2.1019, 2.1018, 2.1018, 2.1018, 2.1018, 2.1018, 2.0955, 2.0886, 2.0827, 1.9146, 1.7324, 0.7497, 1.2348, 1.0504, 2.0568, 1.3962, 1.8419, 1.1616, 2.0504, 1.0999, 0.0252, 2.8244, 2.8097, 2.8046, 2.8038, 2.7446, 2.7296, 2.7004, 2.6877, 2.676, 2.6537, 2.6439, 2.6118, 2.6024, 2.5984, 2.5976, 2.5947, 2.5895, 2.5871, 2.5847, 2.5833, 2.5818, 2.5696, 2.5638, 2.5491, 2.5429, 2.541, 2.539, 2.5384, 2.5069, 2.5057, 2.395, 2.1499, 1.6692, 1.8526, 1.8924, 1.3445, 2.0825, -0.8633, 0.4042, 0.9123, 0.5249, 3.1688, 3.1272, 3.0037, 2.9793, 2.8873, 2.7464, 2.731, 2.6249, 2.4229, 2.349, 2.3262, 2.3243, 2.3238, 2.3238, 2.3238, 2.3238, 2.3238, 2.3238, 2.3238, 2.3238, 2.3055, 2.233, 2.2309, 2.2301, 2.1638, 2.0763, 1.9944, 1.9926, 1.9926, 1.9807, 1.9807, 1.7913, 1.3939, 1.2772, 1.2772, 1.6345, 0.7966, 1.0031, 1.2329, 3.3247, 3.1656, 3.0388, 2.9016, 2.8896, 2.7425, 2.4355, 2.35, 2.3113, 2.2299, 2.1833, 2.1212, 2.1085, 2.0654, 2.0301, 2.002, 1.9949, 1.9949, 1.9949, 1.9949, 1.9949, 1.9949, 1.987, 1.9862, 1.9862, 1.9862, 1.9862, 1.9793, 1.9793, 1.9793, 1.9763, 1.9272, 1.9417, 1.8614, 1.9417, 1.8467, 1.8477, 1.8477, 1.5524, 1.531, 1.7485, 0.8014, 1.261, 1.6969, 1.6941, 1.6896, 1.2456, 0.9204, -0.1319, 2.9566, 2.7446, 2.7057, 2.6938, 2.6584, 2.6358, 2.6258, 2.6258, 2.6258, 2.6258, 2.6157, 2.5285, 2.5092, 2.4977, 2.4977, 2.4977, 2.4977, 2.4977, 2.4977, 2.4977, 2.4931, 2.4924, 2.4924, 2.4915, 2.4155, 2.3883, 2.379, 2.3701, 2.3561, 2.2654, 2.1992, 1.6372, 1.7056, 0.9245, 1.2201, 1.1539, 3.1082, 3.0773, 3.0773, 3.0356, 3.0356, 3.0356, 3.0356, 3.0356, 3.0356, 3.0185, 3.0037, 2.9871, 2.98, 2.857, 2.7744, 2.7744, 2.7717, 2.7684, 2.5766, 2.5398, 2.5282, 2.5282, 2.5243, 2.5243, 2.5076, 2.5076, 2.5076, 2.5076, 2.5076, 2.5076, 2.4621, 2.5076, 2.5076, 2.5076, 2.1348, 2.4115, 2.4115, 2.4569, 1.7585, 2.1735, 1.8435]}, \"token.table\": {\"Topic\": [1, 2, 8, 1, 2, 3, 1, 2, 3, 1, 2, 4, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 8, 1, 2, 5, 1, 2, 3, 8, 1, 2, 7, 1, 2, 4, 1, 2, 3, 8, 1, 2, 3, 1, 2, 6, 1, 2, 3, 1, 2, 8, 1, 2, 6, 1, 2, 3, 8, 1, 2, 8, 1, 2, 5, 1, 2, 8, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 6, 1, 2, 6, 1, 2, 3, 6, 1, 2, 3, 1, 2, 1, 2, 5, 1, 2, 6, 1, 2, 6, 1, 2, 6, 1, 2, 6, 1, 2, 6, 1, 2, 5, 1, 2, 4, 1, 2, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 5, 1, 2, 4, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 4, 1, 2, 7, 1, 2, 3, 1, 2, 6, 1, 2, 3, 4, 1, 2, 8, 1, 2, 3, 7, 1, 2, 4, 1, 2, 6, 1, 2, 3, 5, 1, 2, 3, 1, 2, 7, 1, 2, 3, 1, 2, 6, 1, 2, 3, 1, 2, 3, 6, 1, 2, 8, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 3, 7, 1, 2, 5, 1, 2, 1, 2, 6, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 7, 1, 2, 8, 1, 2, 3, 1, 2, 3, 8, 1, 2, 7, 1, 2, 3, 5, 6, 1, 2, 3, 1, 2, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 1, 2, 5, 1, 2, 5, 1, 2, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 8, 1, 2, 3, 1, 2, 6, 1, 2, 3, 8, 1, 2, 7, 1, 2, 3, 4, 1, 2, 7, 1, 2, 3, 1, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 7, 1, 2, 8, 1, 2, 4, 1, 2, 6, 1, 2, 3, 8, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 8, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 7, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 4, 1, 2, 3, 1, 2, 8, 1, 2, 8, 1, 2, 8, 1, 2, 3, 1, 2, 5, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 1, 2, 8, 1, 2, 1, 2, 6, 1, 2, 3, 1, 2, 3, 8, 1, 2, 3, 4, 6, 1, 2, 3, 6, 1, 2, 6, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 7, 1, 2, 7, 1, 2, 1, 2, 6, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 7, 1, 2, 7, 1, 2, 7, 1, 2, 8, 1, 2, 6, 1, 2, 3, 1, 2, 3, 1, 2, 4, 1, 2, 5, 1, 2, 7, 1, 2, 5, 1, 2, 4, 1, 2, 3, 8, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 7, 1, 2, 3, 8, 1, 2, 3, 7, 1, 2, 1, 2, 6, 1, 2, 4, 1, 2, 6, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 8, 1, 2, 3, 4, 1, 2, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 5, 1, 2, 4, 1, 2, 3, 6, 1, 2, 4, 1, 2, 6, 1, 2, 1, 2, 5, 1, 2, 3, 8, 1, 2, 3, 8, 1, 2, 3, 1, 2, 3, 1, 2, 8, 1, 2, 3, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 6, 1, 2, 3, 5, 1, 2, 4, 1, 2, 3, 8, 1, 2, 3, 1, 2, 5, 1, 2, 8, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 6, 1, 2, 3, 6, 7, 8, 1, 2, 3, 6, 1, 2, 7, 1, 2, 6, 1, 2, 3, 4, 5, 6, 7, 1, 2, 1, 2, 8, 1, 2, 4, 1, 2, 3, 4, 6, 1, 2, 4, 1, 2, 3, 5, 1, 2, 6, 1, 2, 3, 1, 2, 3, 4, 6, 1, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 4, 1, 2, 3, 7, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 1, 2, 3, 1, 2, 8, 1, 2, 4, 1, 2, 4, 1, 2, 6, 1, 2, 3, 1, 2, 4, 5, 1, 2, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 5, 1, 2, 3, 8, 1, 2, 4, 1, 2, 6, 7, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 4, 6, 1, 2, 3, 4, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 8, 1, 2, 3, 8, 1, 2, 3, 8, 1, 2, 3, 5, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 7, 1, 2, 3, 5, 1, 2, 3, 6, 1, 2, 3, 1, 2, 4, 6, 1, 2, 3, 8, 1, 2, 4, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 5, 1, 2, 3, 6, 1, 2, 3, 1, 2, 3, 1, 2, 4, 7, 1, 2, 3, 1, 2, 3, 7, 1, 2, 6, 1, 2, 3, 1, 2, 3, 5, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4, 1, 2, 3, 1, 2, 8, 1, 2, 4, 1, 2, 6, 1, 2, 4, 1, 2, 8, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 7, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 8, 1, 2, 8, 1, 2, 3, 7], \"Freq\": [0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.9528348778130769, 0.015124363139890108, 0.015124363139890108, 0.7287857365868481, 0.2203305715262564, 0.04707918195005479, 0.134680234061636, 0.134680234061636, 0.606061053277362, 0.12360527977520218, 0.3708158393256065, 0.3708158393256065, 0.0058303490677456184, 0.979498643381264, 0.0058303490677456184, 0.13778044757100583, 0.8446540481526879, 0.0059904542422176445, 0.36759959897872857, 0.6256262405695668, 0.003534611528641621, 0.15205581259345852, 0.05068527086448617, 0.20274108345794467, 0.5068527086448616, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.15503628864431523, 0.05167876288143841, 0.20671505152575365, 0.5684663916958225, 0.21542031032066386, 0.21542031032066386, 0.4308406206413277, 0.11517324696433416, 0.11517324696433416, 0.6910394817860049, 0.15205581259345852, 0.05068527086448617, 0.20274108345794467, 0.5068527086448616, 0.960712423382504, 0.01865461016276707, 0.009327305081383535, 0.23527606012792496, 0.23527606012792496, 0.23527606012792496, 0.9225307774727077, 0.04612653887363538, 0.011531634718408845, 0.12370120023402514, 0.4948048009361006, 0.2474024004680503, 0.10242488204501869, 0.10242488204501869, 0.6145492922701121, 0.1193214333674035, 0.238642866734807, 0.1193214333674035, 0.477285733469614, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.16883146619542533, 0.16883146619542533, 0.33766293239085066, 0.22251845840580528, 0.22251845840580528, 0.22251845840580528, 0.9722840447373975, 0.010343447284440399, 0.010343447284440399, 0.4516914037523573, 0.24026138497465813, 0.08649409859087692, 0.22104047417668546, 0.01397361966942876, 0.01397361966942876, 0.01397361966942876, 0.936232517851727, 0.9585662353376017, 0.016816951497150904, 0.016816951497150904, 0.101737888799031, 0.101737888799031, 0.712165221593217, 0.05649232159440482, 0.05649232159440482, 0.05649232159440482, 0.7908925023216675, 0.02877568127236047, 0.02877568127236047, 0.920821800715535, 0.1466500244365882, 0.1466500244365882, 0.1466500244365882, 0.4399500733097646, 0.008164120325826644, 0.008164120325826644, 0.9796944390991974, 0.3076754047693884, 0.5938850836246334, 0.007155241971381125, 0.08586290365657351, 0.24529807931775793, 0.24529807931775793, 0.24529807931775793, 0.046597308293881284, 0.023298654146940642, 0.8853488575837444, 0.11653168171213739, 0.11653168171213739, 0.46612672684854956, 0.23306336342427478, 0.008322857203554945, 0.9737742928159285, 0.008322857203554945, 0.007527730981126823, 0.9786050275464869, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.16704056947480014, 0.16704056947480014, 0.3340811389496003, 0.08816078437814638, 0.08816078437814638, 0.7934470594033174, 0.24671637338972396, 0.24671637338972396, 0.24671637338972396, 0.6329922186057533, 0.00448930651493442, 0.3546552146798192, 0.0074325428734517635, 0.9736631164221811, 0.0074325428734517635, 0.0074325428734517635, 0.9991754915624539, 0.00029587666318106425, 0.00029587666318106425, 0.17024922783241553, 0.17024922783241553, 0.34049845566483106, 0.06062689406890189, 0.06062689406890189, 0.8487765169646265, 0.20901768949633848, 0.20901768949633848, 0.20901768949633848, 0.41803537899267695, 0.026206111340801145, 0.07861833402240344, 0.8648016742464378, 0.010080930956682397, 0.8770409932313684, 0.010080930956682397, 0.10080930956682396, 0.16171329493864414, 0.16171329493864414, 0.3234265898772883, 0.006469640457480463, 0.9833853495370304, 0.006469640457480463, 0.22936950952888988, 0.22936950952888988, 0.45873901905777975, 0.30810346974869707, 0.04053993023009172, 0.6324229115894308, 0.016215972092036686, 0.22188228063809662, 0.22188228063809662, 0.22188228063809662, 0.13948322483196046, 0.2789664496639209, 0.13948322483196046, 0.4184496744958814, 0.024630795979446278, 0.5665083075272644, 0.36946193969169416, 0.2346897566874544, 0.2346897566874544, 0.2346897566874544, 0.07361725666369157, 0.2576603983229205, 0.03680862833184578, 0.6257466816413783, 0.004744984774217845, 0.9869568330373119, 0.004744984774217845, 0.1934120788618733, 0.1934120788618733, 0.3868241577237466, 0.02829004296569594, 0.02829004296569594, 0.933571417867966, 0.43885461418420074, 0.1462848713947336, 0.1462848713947336, 0.9949802769873386, 0.0031093133655854333, 0.0010364377885284778, 0.2134319938499361, 0.2134319938499361, 0.2134319938499361, 0.2134319938499361, 0.22156534160051616, 0.22156534160051616, 0.22156534160051616, 0.0764120750391652, 0.22923622511749558, 0.22923622511749558, 0.382060375195826, 0.20901768949633848, 0.20901768949633848, 0.20901768949633848, 0.41803537899267695, 0.20905391952045208, 0.20905391952045208, 0.20905391952045208, 0.41810783904090415, 0.18707216285783052, 0.37414432571566103, 0.37414432571566103, 0.959019378935902, 0.016254565744676305, 0.11174148037185244, 0.11174148037185244, 0.5587074018592623, 0.9837891558619677, 0.00878383174876757, 0.004391915874383785, 0.9354810697254259, 0.049235845775022415, 0.028779884886048292, 0.028779884886048292, 0.9209563163535454, 0.20336274420502082, 0.20336274420502082, 0.20336274420502082, 0.40672548841004164, 0.1439605649144562, 0.2879211298289124, 0.4318816947433685, 0.028779884886048292, 0.028779884886048292, 0.9209563163535454, 0.15205581259345852, 0.05068527086448617, 0.20274108345794467, 0.5068527086448616, 0.1934120788618733, 0.1934120788618733, 0.3868241577237466, 0.38448669904930677, 0.21970668517103245, 0.10985334258551623, 0.10985334258551623, 0.05492667129275811, 0.8399581161052516, 0.14559274012491027, 0.0055997207740350104, 0.01303037961767559, 0.9772784713256693, 0.13332811840598477, 0.13332811840598477, 0.13332811840598477, 0.5333124736239391, 0.596878244575959, 0.39687715738820306, 0.0031250169873086858, 0.028779884886048292, 0.028779884886048292, 0.9209563163535454, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.1695424156680981, 0.1695424156680981, 0.3390848313361962, 0.5140734497700301, 0.25703672488501506, 0.12851836244250753, 0.014812283331893177, 0.9702045582390031, 0.0074061416659465884, 0.01187608286530681, 0.5106715632081928, 0.16626516011429535, 0.29690207163267024, 0.06626287033876252, 0.06626287033876252, 0.5963658330488627, 0.19878861101628756, 0.9808616429989916, 0.0112742717586091, 0.00563713587930455, 0.2666501878653971, 0.2666501878653971, 0.2666501878653971, 0.1433334545027593, 0.2866669090055186, 0.1433334545027593, 0.4300003635082779, 0.21542031032066386, 0.21542031032066386, 0.4308406206413277, 0.7047251786522402, 0.2912384666879156, 0.0017977683128883677, 0.0017977683128883677, 0.1934120788618733, 0.1934120788618733, 0.3868241577237466, 0.9600156876719653, 0.016842380485473075, 0.016842380485473075, 0.05442142023712098, 0.05442142023712098, 0.8163213035568146, 0.9843799393415658, 0.010937554881572952, 0.002734388720393238, 0.942421037071954, 0.020487413849390304, 0.020487413849390304, 0.5809686282845185, 0.4055818725759846, 0.007307781487855578, 0.18584018818912376, 0.18584018818912376, 0.18584018818912376, 0.3716803763782475, 0.18164438497984148, 0.8083175131602945, 0.004541109624496037, 0.0160762133623946, 0.0643048534495784, 0.9002679482940975, 0.00866474192999024, 0.9704510961589068, 0.00866474192999024, 0.1926027203896021, 0.1926027203896021, 0.3852054407792042, 0.22185935229060452, 0.22185935229060452, 0.22185935229060452, 0.9551408595954872, 0.010731919770735811, 0.021463839541471623, 0.48288882895573937, 0.16096294298524647, 0.16096294298524647, 0.05600685551770671, 0.6440788384536272, 0.11201371103541342, 0.14001713879426678, 0.012340050718932167, 0.012340050718932167, 0.962523956076709, 0.07426670807611135, 0.5198669565327795, 0.07426670807611135, 0.07426670807611135, 0.22280012422833403, 0.15725416883889332, 0.0524180562796311, 0.2096722251185244, 0.5765986190759421, 0.008009979664983407, 0.06407983731986726, 0.9211476614730918, 0.008009979664983407, 0.0025283472266447384, 0.9911121128447374, 0.0025283472266447384, 0.0025283472266447384, 0.008974915843196714, 0.969290911065245, 0.008974915843196714, 0.008974915843196714, 0.04133668790891748, 0.08267337581783496, 0.08267337581783496, 0.7440603823605147, 0.0024950466306163954, 0.9930285589853254, 0.0024950466306163954, 0.764266396344949, 0.054590456881782067, 0.10918091376356413, 0.009168388742686516, 0.976433401096114, 0.009168388742686516, 0.3099320809942061, 0.15496604049710305, 0.3099320809942061, 0.9517670729047262, 0.013996574601540092, 0.013996574601540092, 0.06587705894483196, 0.06587705894483196, 0.7905247073379835, 0.968781887507163, 0.01562551431463166, 0.00781275715731583, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.22185935229060452, 0.22185935229060452, 0.22185935229060452, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.9941669646531229, 0.0027387519687413855, 0.0027387519687413855, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.13886720370167502, 0.4166016111050251, 0.13886720370167502, 0.27773440740335004, 0.008904899412411795, 0.008904899412411795, 0.9706340359528856, 0.02871773656676816, 0.02871773656676816, 0.9189675701365811, 0.14418088021124953, 0.28836176042249906, 0.4325426406337486, 0.9786722889030464, 0.0084368300767504, 0.48288882895573937, 0.16096294298524647, 0.16096294298524647, 0.005965596365201565, 0.9843234002582583, 0.005965596365201565, 0.15024015564293747, 0.05008005188097916, 0.20032020752391663, 0.5008005188097916, 0.26270348415810096, 0.4378391402635016, 0.08756782805270032, 0.08756782805270032, 0.17513565610540063, 0.16169243446362006, 0.16169243446362006, 0.16169243446362006, 0.3233848689272401, 0.5636940438335054, 0.14092351095837635, 0.14092351095837635, 0.005243001195197152, 0.9856842246970645, 0.005243001195197152, 0.10942006669163745, 0.7692562264381785, 0.11273582628835374, 0.0033157595967162868, 0.9843393477210871, 0.007981129846387193, 0.005320753230924795, 0.012839294681059344, 0.8345541542688574, 0.012839294681059344, 0.14123224149165278, 0.0763727314735853, 0.0763727314735853, 0.763727314735853, 0.799731319327306, 0.19098061357069995, 0.0059681441740843735, 0.03033594215158683, 0.03033594215158683, 0.910078264547605, 0.9725236533005116, 0.011577662539291805, 0.9092645323494938, 0.0691831709396354, 0.009883310134233629, 0.5831662054056782, 0.028825705970622877, 0.3836036256090583, 0.0022173619977402213, 0.17482526584173255, 0.08741263292086628, 0.6118884304460639, 0.010545283362017236, 0.010545283362017236, 0.9701660693055858, 0.2498702611338131, 0.12493513056690655, 0.12493513056690655, 0.458095478745324, 0.027163584136892713, 0.01810905609126181, 0.004527264022815452, 0.9461981807684294, 0.13896318878207037, 0.06948159439103518, 0.06948159439103518, 0.694815943910352, 0.1760960939291133, 0.3521921878582266, 0.3521921878582266, 0.20901768949633848, 0.20901768949633848, 0.20901768949633848, 0.41803537899267695, 0.1934120788618733, 0.1934120788618733, 0.3868241577237466, 0.9839200597739581, 0.0056873991894448445, 0.06452860716378077, 0.06452860716378077, 0.7743432859653693, 0.16128849250949306, 0.32257698501898613, 0.16128849250949306, 0.32257698501898613, 0.010824287432374471, 0.9633615814813279, 0.010824287432374471, 0.20135379154709868, 0.20135379154709868, 0.20135379154709868, 0.40270758309419735, 0.008602819574521714, 0.6452114680891285, 0.33550996340634687, 0.004593981824769044, 0.9877060923253446, 0.0028672468583696136, 0.6738030117168592, 0.3182644012790271, 0.025841174704860647, 0.025841174704860647, 0.9302822893749833, 0.02296861863867602, 0.04593723727735204, 0.9187447455470409, 0.34005280961323603, 0.17002640480661801, 0.08501320240330901, 0.17002640480661801, 0.17002640480661801, 0.1934120788618733, 0.1934120788618733, 0.3868241577237466, 0.1934120788618733, 0.1934120788618733, 0.3868241577237466, 0.22156534160051616, 0.22156534160051616, 0.22156534160051616, 0.2606265925620505, 0.2606265925620505, 0.2606265925620505, 0.006522481442143616, 0.5348434782557765, 0.45005121950790955, 0.014394576336329148, 0.04318372900898745, 0.9356474618613947, 0.10699182818810814, 0.10699182818810814, 0.748942797316757, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.3425088126696827, 0.17125440633484135, 0.3425088126696827, 0.32653413609932097, 0.16326706804966049, 0.32653413609932097, 0.1401442801450477, 0.07007214007252385, 0.7007214007252385, 0.923705338299002, 0.02252939849509761, 0.03754899749182935, 0.0075097994983658704, 0.1760960939291133, 0.3521921878582266, 0.3521921878582266, 0.008315844803690483, 0.008315844803690483, 0.9729538420317866, 0.22269865082278475, 0.00890794603291139, 0.7571754127974681, 0.1934120788618733, 0.1934120788618733, 0.3868241577237466, 0.15503628864431523, 0.05167876288143841, 0.20671505152575365, 0.5684663916958225, 0.20914964668202277, 0.20914964668202277, 0.20914964668202277, 0.41829929336404553, 0.9547900860499529, 0.01948551196020312, 0.2666501878653971, 0.2666501878653971, 0.2666501878653971, 0.04454726866085074, 0.04454726866085074, 0.890945373217015, 0.2346897566874544, 0.2346897566874544, 0.2346897566874544, 0.22388056867585654, 0.22388056867585654, 0.22388056867585654, 0.22388056867585654, 0.6682295401063073, 0.32756350005211143, 0.0018717914288692082, 0.19573064827596948, 0.04893266206899237, 0.19573064827596948, 0.48932662068992366, 0.3456332550956126, 0.6474862978791143, 0.0023042217006374174, 0.0023042217006374174, 0.42673255132262883, 0.1422441837742096, 0.1422441837742096, 0.9672031944044976, 0.009576269251529679, 0.009576269251529679, 0.2058228012214055, 0.2058228012214055, 0.2058228012214055, 0.411645602442811, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.4301682301549597, 0.04301682301549597, 0.47318505317045567, 0.2275594518758337, 0.5309720543769453, 0.0758531506252779, 0.0758531506252779, 0.08299479946578173, 0.08299479946578173, 0.7469531951920355, 0.2666501878653971, 0.2666501878653971, 0.2666501878653971, 0.01291505016620483, 0.9686287624653622, 0.15261824127130277, 0.15261824127130277, 0.6104729650852111, 0.15205581259345852, 0.05068527086448617, 0.20274108345794467, 0.5068527086448616, 0.15205581259345852, 0.05068527086448617, 0.20274108345794467, 0.5068527086448616, 0.025028962214221746, 0.06257240553555436, 0.888528158604872, 0.030072402024080444, 0.030072402024080444, 0.9021720607224133, 0.5421158137396977, 0.1807052712465659, 0.1807052712465659, 0.015182344523251193, 0.9564877049648252, 0.015182344523251193, 0.9486837725124112, 0.015811396208540187, 0.015811396208540187, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.016950297248998512, 0.016950297248998512, 0.9492166459439166, 0.031226683615856024, 0.031226683615856024, 0.9055738248598247, 0.1745108846975277, 0.8202011580783803, 0.12061017601044104, 0.48244070404176415, 0.24122035202088207, 0.038475901611653145, 0.11542770483495944, 0.038475901611653145, 0.7695180322330629, 0.02168390363215149, 0.02168390363215149, 0.9324078561825141, 0.1282017885441047, 0.5128071541764188, 0.1282017885441047, 0.2564035770882094, 0.699682967376471, 0.2895239865006087, 0.004825399775010144, 0.12420941455771718, 0.37262824367315156, 0.37262824367315156, 0.14418088021124953, 0.28836176042249906, 0.4325426406337486, 0.015712777876937006, 0.015712777876937006, 0.9584794504931574, 0.02466158044117817, 0.02466158044117817, 0.9124784763235922, 0.9778746981957391, 0.006652208831263532, 0.006652208831263532, 0.32458689745078645, 0.3895042769409437, 0.06491737949015729, 0.19475213847047185, 0.14766392614926538, 0.36915981537316345, 0.07383196307463269, 0.14766392614926538, 0.14766392614926538, 0.07383196307463269, 0.15114740920144615, 0.7773295330360087, 0.021592487028778022, 0.021592487028778022, 0.1933143733182686, 0.1933143733182686, 0.3866287466365372, 0.5430036811463551, 0.09050061352439252, 0.18100122704878505, 0.02789904281478248, 0.753274155999127, 0.02789904281478248, 0.02789904281478248, 0.1394952140739124, 0.02789904281478248, 0.02789904281478248, 0.010821227703094082, 0.9739104932784673, 0.13556072007036507, 0.4066821602110952, 0.27112144014073014, 0.09209290388219601, 0.09209290388219601, 0.7367432310575681, 0.37305854652628695, 0.09326463663157174, 0.09326463663157174, 0.09326463663157174, 0.27979390989471525, 0.09147359759286082, 0.09147359759286082, 0.7317887807428866, 0.13615396982948524, 0.03890113423699579, 0.019450567118497894, 0.7974732518584137, 0.5622211615350234, 0.14055529038375586, 0.14055529038375586, 0.9431372341972325, 0.038235293278266184, 0.01274509775942206, 0.5984818568511762, 0.11969637137023523, 0.059848185685117614, 0.11969637137023523, 0.059848185685117614, 0.1161477330580172, 0.0580738665290086, 0.7549602648771118, 0.009630945972951312, 0.05778567583770787, 0.9149398674303746, 0.9992566212176388, 0.00032161461899505596, 0.00032161461899505596, 0.00123429563999949, 0.9979280249395877, 0.13901032455443887, 0.6006094938764305, 0.23610532223940953, 0.023875819102861635, 0.18458596869572425, 0.18458596869572425, 0.18458596869572425, 0.3691719373914485, 0.08023769451139365, 0.08023769451139365, 0.08023769451139365, 0.7221392506025428, 0.028779884886048292, 0.028779884886048292, 0.9209563163535454, 0.12005060087127434, 0.7653225805543739, 0.015006325108909292, 0.09003795065345575, 0.003067667600350866, 0.003067667600350866, 0.9908566349133296, 0.003067667600350866, 0.02789904281478248, 0.753274155999127, 0.02789904281478248, 0.02789904281478248, 0.1394952140739124, 0.02789904281478248, 0.02789904281478248, 0.01240723410956901, 0.9553570264368136, 0.01240723410956901, 0.007998651274858777, 0.9758354555327707, 0.007998651274858777, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.05152725487621532, 0.05152725487621532, 0.8244360780194451, 0.9597018266410312, 0.018107581634736438, 0.018107581634736438, 0.43885461418420074, 0.1462848713947336, 0.1462848713947336, 0.011978724609984464, 0.9582979687987571, 0.011978724609984464, 0.0683949052991032, 0.5471592423928257, 0.1367898105982064, 0.20518471589730963, 0.01883802648720845, 0.01883802648720845, 0.9419013243604225, 0.012588881252136369, 0.012588881252136369, 0.012588881252136369, 0.956754975162364, 0.11556832360487058, 0.11556832360487058, 0.6934099416292235, 0.08861009215214471, 0.35444036860857886, 0.4430504607607236, 0.14823235188243986, 0.04941078396081328, 0.24705391980406644, 0.49410783960813287, 0.06414329627486073, 0.06414329627486073, 0.8338628515731895, 0.6717284650034966, 0.11195474416724943, 0.055977372083624716, 0.11195474416724943, 0.3099320809942061, 0.15496604049710305, 0.3099320809942061, 0.9668537457416473, 0.011510163639781515, 0.011510163639781515, 0.008967143957743826, 0.008967143957743826, 0.9684515474363332, 0.00915114903251508, 0.00915114903251508, 0.9791729464791136, 0.8300810583184712, 0.0251539714641961, 0.0503079429283922, 0.0754619143925883, 0.11335017654812209, 0.11335017654812209, 0.11335017654812209, 0.11335017654812209, 0.5667508827406105, 0.050847015709012525, 0.23728607330872512, 0.6949092146898379, 0.2774995985376681, 0.5549991970753362, 0.0252272362306971, 0.1009089449227884, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.16359598380074175, 0.16359598380074175, 0.16359598380074175, 0.3271919676014835, 0.15205581259345852, 0.05068527086448617, 0.20274108345794467, 0.5068527086448616, 0.09651967912783675, 0.6997676736768165, 0.024129919781959188, 0.1689094384737143, 0.0037461746819136325, 0.9702592426156309, 0.022477048091481797, 0.026123084613441303, 0.07836925384032391, 0.8620617922435629, 0.9830330420638681, 0.008816439839137831, 0.0044082199195689155, 0.21804816703180865, 0.21804816703180865, 0.21804816703180865, 0.21804816703180865, 0.011844937263989077, 0.9712848556471042, 0.011844937263989077, 0.20901768949633848, 0.20901768949633848, 0.20901768949633848, 0.41803537899267695, 0.028204109196659895, 0.04230616379498984, 0.014102054598329947, 0.9025314942931166, 0.3066974859417515, 0.15334874297087575, 0.15334874297087575, 0.3066974859417515, 0.5746974268627881, 0.42243992675888065, 0.001492720589253995, 0.2903271907867719, 0.2903271907867719, 0.14516359539338594, 0.14516359539338594, 0.14975651883830332, 0.049918839612767774, 0.24959419806383887, 0.49918839612767774, 0.5385931059808634, 0.0797915712564242, 0.3590620706539089, 0.013662341082863473, 0.9563638758004431, 0.012838793013398209, 0.9629094760048656, 0.012838793013398209, 0.9702062502748807, 0.010901193823313267, 0.010901193823313267, 0.1702650710723089, 0.1702650710723089, 0.3405301421446178, 0.2724677533843883, 0.13623387669219414, 0.13623387669219414, 0.2724677533843883, 0.006397810568828143, 0.006397810568828143, 0.985262827599534, 0.02877871598159828, 0.02877871598159828, 0.920918911411145, 0.0955377496644121, 0.3821509986576484, 0.0955377496644121, 0.2866132489932363, 0.48986016418675005, 0.5034673909697154, 0.00340180669574132, 0.23758605274807357, 0.23758605274807357, 0.23758605274807357, 0.23758605274807357, 0.2346897566874544, 0.2346897566874544, 0.2346897566874544, 0.3283382785422484, 0.6686161308496695, 0.001193957376517267, 0.22308204258369696, 0.22308204258369696, 0.22308204258369696, 0.22308204258369696, 0.003626238713780953, 0.9899631688622001, 0.7139543350858076, 0.28242419643443495, 0.0017541875554933847, 0.0017541875554933847, 0.08196950862371523, 0.08196950862371523, 0.08196950862371523, 0.737725577613437, 0.08000831317400675, 0.08000831317400675, 0.7200748185660608, 0.003955027750026156, 0.9887569375065389, 0.003955027750026156, 0.12370120023402514, 0.4948048009361006, 0.2474024004680503, 0.08896758221110318, 0.08896758221110318, 0.8007082398999286, 0.2346897566874544, 0.2346897566874544, 0.2346897566874544, 0.0481494830841897, 0.0481494830841897, 0.8666906955154146, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.9882070419215421, 0.004451383071718658, 0.004451383071718658, 0.9500337379053965, 0.017273340689189027, 0.017273340689189027, 0.20147640325415592, 0.7894585596897538, 0.004111763331717468, 0.07760571104426393, 0.07760571104426393, 0.7760571104426394, 0.06476424319576014, 0.06476424319576014, 0.1295284863915203, 0.7771709183491218, 0.6558575360538074, 0.3366735351742878, 0.004372383573692049, 0.003789614929860822, 0.9549829623249272, 0.03789614929860822, 0.003789614929860822, 0.23893655564733152, 0.23893655564733152, 0.23893655564733152, 0.23893655564733152, 0.019111510640027446, 0.019111510640027446, 0.9364640213613449, 0.6701326801260701, 0.3230996850607838, 0.0029916637505628127, 0.9505209311322063, 0.016675805809336954, 0.39722866319869876, 0.552031009886427, 0.04673278390572927, 0.007321741822740128, 0.973791662424437, 0.007321741822740128, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.1928059564403716, 0.1928059564403716, 0.3856119128807432, 0.03129545468428455, 0.03129545468428455, 0.8136818217913984, 0.0625909093685691], \"Term\": [\".\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\", \".\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\", \".\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\", \"..\", \"..\", \"..\", \"...\", \"...\", \"...\", \"101\", \"101\", \"101\", \"10:00\", \"10:00\", \"10:00\", \"19\", \"19\", \"19\", \"2020\", \"2020\", \"2020\", \"2021\", \"2021\", \"2021\", \"6miles\", \"6miles\", \"6miles\", \"6miles\", \"actress\", \"actress\", \"actress\", \"akafit\", \"akafit\", \"akafit\", \"akafit\", \"alexia\", \"alexia\", \"alexia\", \"allnatural\", \"allnatural\", \"allnatural\", \"allyouhaveistime\", \"allyouhaveistime\", \"allyouhaveistime\", \"allyouhaveistime\", \"almost\", \"almost\", \"almost\", \"alternativemedicine\", \"alternativemedicine\", \"alternativemedicine\", \"always\", \"always\", \"always\", \"annie\", \"annie\", \"annie\", \"appointment\", \"appointment\", \"appointment\", \"athlete\", \"athlete\", \"athlete\", \"athlete\", \"atlyoga\", \"atlyoga\", \"atlyoga\", \"audition\", \"audition\", \"audition\", \"autoimmunedisease\", \"autoimmunedisease\", \"autoimmunedisease\", \"bath\", \"bath\", \"bath\", \"beautiful\", \"beautiful\", \"beautiful\", \"beautiful\", \"beauty\", \"beauty\", \"beauty\", \"beauty\", \"bed\", \"bed\", \"bed\", \"betteryou\", \"betteryou\", \"betteryou\", \"bio\", \"bio\", \"bio\", \"bio\", \"blackblogger\", \"blackblogger\", \"blackblogger\", \"blackownedbusiness\", \"blackownedbusiness\", \"blackownedbusiness\", \"blackownedbusiness\", \"bliss\", \"bliss\", \"bliss\", \"body\", \"body\", \"body\", \"body\", \"bodybutter\", \"bodybutter\", \"bodybutter\", \"book\", \"book\", \"book\", \"breaker\", \"breaker\", \"breaker\", \"breaker\", \"breathe\", \"breathe\", \"breathe\", \"breathing\", \"breathing\", \"broadway\", \"broadway\", \"broadway\", \"brookiegirl\", \"brookiegirl\", \"brookiegirl\", \"brookiegirlannapolis\", \"brookiegirlannapolis\", \"brookiegirlannapolis\", \"brookiegirlmontgomery\", \"brookiegirlmontgomery\", \"brookiegirlmontgomery\", \"brookiegirlnationalharbor\", \"brookiegirlnationalharbor\", \"brookiegirlnationalharbor\", \"brookiegirltysons\", \"brookiegirltysons\", \"brookiegirltysons\", \"bts\", \"bts\", \"bts\", \"butter\", \"butter\", \"butter\", \"buyblack\", \"buyblack\", \"buyblack\", \"call\", \"call\", \"call\", \"calm\", \"calm\", \"calm\", \"calm\", \"care\", \"care\", \"care\", \"cast\", \"cast\", \"cast\", \"cbd\", \"cbd\", \"cbd\", \"cdcdivorcecoach\", \"cdcdivorcecoach\", \"cdcdivorcecoach\", \"cdcdivorcecoach\", \"chakrahealing\", \"chakrahealing\", \"chakrahealing\", \"challenge\", \"challenge\", \"challenge\", \"challenge\", \"character\", \"character\", \"character\", \"check\", \"check\", \"check\", \"chiropractic\", \"chiropractic\", \"chiropractic\", \"christmas\", \"christmas\", \"christmas\", \"christmas\", \"chronicillness\", \"chronicillness\", \"chronicillness\", \"clarity\", \"clarity\", \"clarity\", \"clarity\", \"click\", \"click\", \"click\", \"coloradolife\", \"coloradolife\", \"coloradolife\", \"could\", \"could\", \"could\", \"could\", \"covid\", \"covid\", \"covid\", \"crismuss\", \"crismuss\", \"crismuss\", \"dailyinspiration\", \"dailyinspiration\", \"dailyinspiration\", \"damper\", \"damper\", \"damper\", \"day\", \"day\", \"day\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"digestivehealth\", \"digestivehealth\", \"digestivehealth\", \"divorce\", \"divorce\", \"divorce\", \"divorce\", \"divorcecoach\", \"divorcecoach\", \"divorcecoach\", \"divorcecoach\", \"divorcemediation\", \"divorcemediation\", \"divorcemediation\", \"divorcemediation\", \"dnr\", \"dnr\", \"dnr\", \"do\", \"do\", \"doctor\", \"doctor\", \"doctor\", \"dont\", \"dont\", \"dont\", \"eat\", \"eat\", \"ebonyinsights\", \"ebonyinsights\", \"ebonyinsights\", \"eliminatebullying\", \"eliminatebullying\", \"eliminatebullying\", \"eliminatebullying\", \"emdr\", \"emdr\", \"emdr\", \"empathhealer\", \"empathhealer\", \"empathhealer\", \"enjoythescenery\", \"enjoythescenery\", \"enjoythescenery\", \"enjoythescenery\", \"erbahdee\", \"erbahdee\", \"erbahdee\", \"eve\", \"eve\", \"eve\", \"eve\", \"eve\", \"every\", \"every\", \"every\", \"exercise\", \"exercise\", \"fall\", \"fall\", \"fall\", \"fall\", \"feel\", \"feel\", \"feel\", \"femaleblogger\", \"femaleblogger\", \"femaleblogger\", \"femaledirector\", \"femaledirector\", \"femaledirector\", \"film\", \"film\", \"film\", \"final\", \"final\", \"final\", \"find\", \"find\", \"find\", \"fitness\", \"fitness\", \"fitness\", \"fitness\", \"fitnessmotivation\", \"fitnessmotivation\", \"fitnessmotivation\", \"fitnessmotivation\", \"form\", \"form\", \"form\", \"frontier\", \"frontier\", \"frontier\", \"gary\", \"gary\", \"gary\", \"gary\", \"georghiou\", \"georghiou\", \"georghiou\", \"get\", \"get\", \"get\", \"get\", \"giftfromafriend\", \"giftfromafriend\", \"giftfromafriend\", \"glass\", \"glass\", \"glass\", \"glow\", \"glow\", \"glow\", \"go\", \"go\", \"go\", \"gonna\", \"gonna\", \"gonna\", \"good\", \"good\", \"good\", \"google\", \"google\", \"google\", \"google\", \"great\", \"great\", \"great\", \"growth\", \"growth\", \"growth\", \"guide\", \"guide\", \"guide\", \"guitar\", \"guitar\", \"guitar\", \"guthealthy\", \"guthealthy\", \"guthealthy\", \"hair\", \"hair\", \"hair\", \"halsey\", \"halsey\", \"halsey\", \"handbook\", \"handbook\", \"handbook\", \"handbook\", \"happiness\", \"happiness\", \"happiness\", \"happynewyear\", \"happynewyear\", \"happynewyear\", \"happynewyear\", \"happynewyear\", \"harmony\", \"harmony\", \"harmony\", \"harmony\", \"heal\", \"heal\", \"heal\", \"heal\", \"health\", \"health\", \"health\", \"health\", \"healthy\", \"healthy\", \"healthy\", \"healthy\", \"healthylifestyle\", \"healthylifestyle\", \"healthylifestyle\", \"healthylifestyle\", \"help\", \"help\", \"help\", \"hit\", \"hit\", \"hit\", \"holiday\", \"holiday\", \"holiday\", \"holler\", \"holler\", \"holler\", \"hour\", \"hour\", \"hour\", \"hydrate\", \"hydrate\", \"hydrate\", \"i'm\", \"i'm\", \"i'm\", \"iamstephf_yoga\", \"iamstephf_yoga\", \"iamstephf_yoga\", \"ibsdiet\", \"ibsdiet\", \"ibsdiet\", \"igyogafam\", \"igyogafam\", \"igyogafam\", \"im\", \"im\", \"im\", \"imdb\", \"imdb\", \"imdb\", \"innovation\", \"innovation\", \"innovation\", \"innovation\", \"inspiration\", \"inspiration\", \"inspiration\", \"inspirationalquotes\", \"inspirationalquotes\", \"inspirationalquotes\", \"israel\", \"israel\", \"israel\", \"ive\", \"ive\", \"jax\", \"jax\", \"jax\", \"join\", \"join\", \"join\", \"justdoit\", \"justdoit\", \"justdoit\", \"justdoit\", \"lady\", \"lady\", \"lady\", \"lady\", \"lady\", \"lake\", \"lake\", \"lake\", \"lake\", \"lawn\", \"lawn\", \"lawn\", \"learn\", \"learn\", \"learn\", \"life\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"link\", \"link\", \"link\", \"link\", \"lip\", \"lip\", \"lip\", \"little\", \"little\", \"little\", \"livelyrics\", \"livelyrics\", \"livelyrics\", \"lol\", \"lol\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"lovely\", \"lovely\", \"lovely\", \"loveyourself\", \"loveyourself\", \"loveyourself\", \"luxury\", \"luxury\", \"luxury\", \"luxury\", \"make\", \"make\", \"make\", \"make\", \"makeup\", \"makeup\", \"makeup\", \"makeup\", \"marismith\", \"marismith\", \"marismith\", \"maritalmediation\", \"maritalmediation\", \"maritalmediation\", \"maritalmediation\", \"marr\", \"marr\", \"marr\", \"mask\", \"mask\", \"massage\", \"massage\", \"massage\", \"massagetherapy\", \"massagetherapy\", \"massagetherapy\", \"massagetherapy\", \"may\", \"may\", \"may\", \"mediation\", \"mediation\", \"mediation\", \"mediation\", \"meditation\", \"meditation\", \"meditation\", \"mental\", \"mental\", \"mentalhealth\", \"mentalhealth\", \"mentalhealth\", \"mentalhealthawareness\", \"mentalhealthawareness\", \"mentalhealthawareness\", \"mentalhealthmatters\", \"mentalhealthmatters\", \"mentalhealthmatters\", \"merrychristmas\", \"merrychristmas\", \"merrychristmas\", \"merrychristmas\", \"merrychristmas\", \"mha\", \"mha\", \"mha\", \"mhfa\", \"mhfa\", \"mhfa\", \"microbiome\", \"microbiome\", \"microbiome\", \"microblading\", \"microblading\", \"microblading\", \"mindfulness\", \"mindfulness\", \"mindfulness\", \"mindset\", \"mindset\", \"mindset\", \"mineral\", \"mineral\", \"mineral\", \"mini-cookie\", \"mini-cookie\", \"mini-cookie\", \"mirror\", \"mirror\", \"mirror\", \"mm\", \"mm\", \"mm\", \"moisturize\", \"moisturize\", \"moisturize\", \"morning\", \"morning\", \"morning\", \"morning\", \"mothernaturenet\", \"mothernaturenet\", \"mothernaturenet\", \"motivation\", \"motivation\", \"motivation\", \"music\", \"music\", \"music\", \"musicislife\", \"musicislife\", \"musicislife\", \"mylifestyle\", \"mylifestyle\", \"mylifestyle\", \"mylifestyle\", \"nadpdivorceprofessional\", \"nadpdivorceprofessional\", \"nadpdivorceprofessional\", \"nadpdivorceprofessional\", \"nail\", \"nail\", \"nasa\", \"nasa\", \"nasa\", \"natural\", \"natural\", \"natural\", \"naturalmedicine\", \"naturalmedicine\", \"naturalmedicine\", \"neckpain\", \"neckpain\", \"neckpain\", \"neckpain\", \"need\", \"need\", \"need\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"neighborhood\", \"new\", \"new\", \"new\", \"new\", \"newtonstyleme\", \"newtonstyleme\", \"newtonstyleme\", \"night\", \"night\", \"night\", \"north\", \"north\", \"north\", \"north\", \"offbroadway\", \"offbroadway\", \"offbroadway\", \"oil\", \"oil\", \"oil\", \"opening\", \"opening\", \"opening\", \"opening\", \"organic\", \"organic\", \"organic\", \"outfitoftheday\", \"outfitoftheday\", \"outfitoftheday\", \"pandemic\", \"pandemic\", \"park\", \"park\", \"park\", \"pastorlife\", \"pastorlife\", \"pastorlife\", \"pastorlife\", \"payattentiontothehiddengems\", \"payattentiontothehiddengems\", \"payattentiontothehiddengems\", \"payattentiontothehiddengems\", \"peace\", \"peace\", \"peace\", \"personaldevelopment\", \"personaldevelopment\", \"personaldevelopment\", \"phrase\", \"phrase\", \"phrase\", \"physical\", \"physical\", \"physical\", \"play\", \"play\", \"play\", \"playbill\", \"playbill\", \"playbill\", \"positivevibes\", \"positivevibes\", \"positivevibes\", \"positivity\", \"positivity\", \"positivity\", \"practice\", \"practice\", \"press\", \"press\", \"press\", \"priority\", \"priority\", \"priority\", \"priority\", \"product\", \"product\", \"product\", \"psychologist\", \"psychologist\", \"psychologist\", \"psychologist\", \"put\", \"put\", \"put\", \"qcr\", \"qcr\", \"qcr\", \"quinn\", \"quinn\", \"quinn\", \"quote\", \"quote\", \"quote\", \"quoteoftheday\", \"quoteoftheday\", \"quoteoftheday\", \"really\", \"really\", \"really\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommendation\", \"reflexology\", \"reflexology\", \"reflexology\", \"reflexology\", \"reflexology\", \"reflexology\", \"relaxation\", \"relaxation\", \"relaxation\", \"relaxation\", \"reputationintelligence\", \"reputationintelligence\", \"reputationintelligence\", \"reschedule\", \"reschedule\", \"reschedule\", \"resilence\", \"resilence\", \"resilence\", \"resilence\", \"resilence\", \"resilence\", \"resilence\", \"resource\", \"resource\", \"saam\", \"saam\", \"saam\", \"sale\", \"sale\", \"sale\", \"salon\", \"salon\", \"salon\", \"salon\", \"salon\", \"sample\", \"sample\", \"sample\", \"saturday\", \"saturday\", \"saturday\", \"saturday\", \"saturdaymorning\", \"saturdaymorning\", \"saturdaymorning\", \"say\", \"say\", \"say\", \"scent\", \"scent\", \"scent\", \"scent\", \"scent\", \"scrub\", \"scrub\", \"scrub\", \"season\", \"season\", \"season\", \"self\", \"self\", \"self\", \"self-care\", \"self-care\", \"selfcare\", \"selfcare\", \"selfcare\", \"selfcare\", \"selfcareishealthy\", \"selfcareishealthy\", \"selfcareishealthy\", \"selfcareishealthy\", \"selfcaresunday\", \"selfcaresunday\", \"selfcaresunday\", \"selfcaresunday\", \"selfhealer\", \"selfhealer\", \"selfhealer\", \"selfish\", \"selfish\", \"selfish\", \"selfish\", \"selflove\", \"selflove\", \"selflove\", \"selflove\", \"selfnurture\", \"selfnurture\", \"selfnurture\", \"selfnurture\", \"selfnurture\", \"selfnurture\", \"selfnurture\", \"series\", \"series\", \"series\", \"share\", \"share\", \"share\", \"shelbyadina\", \"shelbyadina\", \"shelbyadina\", \"shop\", \"shop\", \"shop\", \"shower\", \"shower\", \"shower\", \"shun\", \"shun\", \"shun\", \"simple\", \"simple\", \"simple\", \"sketch\", \"sketch\", \"sketch\", \"sketch\", \"skin\", \"skin\", \"skin\", \"skincare\", \"skincare\", \"skincare\", \"skincare\", \"skincareroutine\", \"skincareroutine\", \"skincareroutine\", \"slime\", \"slime\", \"slime\", \"slowdown\", \"slowdown\", \"slowdown\", \"slowdown\", \"soap\", \"soap\", \"soap\", \"sock\", \"sock\", \"sock\", \"sock\", \"soldier\", \"soldier\", \"soldier\", \"sometimes\", \"sometimes\", \"sometimes\", \"soul\", \"soul\", \"soul\", \"soundhound\", \"soundhound\", \"soundhound\", \"spa\", \"spa\", \"spa\", \"spa\", \"spaday\", \"spaday\", \"spaday\", \"spaday\", \"spaday\", \"spiritual\", \"spiritual\", \"spiritual\", \"sponsor\", \"sponsor\", \"sponsor\", \"sponsor\", \"springbloomsyogachallenge\", \"springbloomsyogachallenge\", \"springbloomsyogachallenge\", \"staystrong\", \"staystrong\", \"staystrong\", \"staystrong\", \"stoprushingeverywhere\", \"stoprushingeverywhere\", \"stoprushingeverywhere\", \"stoprushingeverywhere\", \"storm\", \"storm\", \"storm\", \"storm\", \"stress\", \"stress\", \"stress\", \"success\", \"success\", \"success\", \"sunday\", \"sunday\", \"sunday\", \"sundaymotivation\", \"sundaymotivation\", \"sundaymotivation\", \"sundaymotivation\", \"support\", \"support\", \"support\", \"supremecourtmediator\", \"supremecourtmediator\", \"supremecourtmediator\", \"supremecourtmediator\", \"sure\", \"sure\", \"sure\", \"sure\", \"sweet\", \"sweet\", \"sweet\", \"sweet\", \"take\", \"take\", \"take\", \"takedown\", \"takedown\", \"takedown\", \"takedown\", \"takeyourtime\", \"takeyourtime\", \"takeyourtime\", \"takeyourtime\", \"tea\", \"tea\", \"tea\", \"teacher\", \"teacher\", \"team\", \"team\", \"team\", \"thats\", \"thats\", \"thats\", \"theatre\", \"theatre\", \"theatre\", \"therapeutic\", \"therapeutic\", \"therapeutic\", \"therapeutic\", \"therapy\", \"therapy\", \"therapy\", \"therapymemes\", \"therapymemes\", \"therapymemes\", \"theyre\", \"theyre\", \"theyre\", \"theyre\", \"thing\", \"thing\", \"thing\", \"thinkbigsundaywithmarsha\", \"thinkbigsundaywithmarsha\", \"thinkbigsundaywithmarsha\", \"thinkbigsundaywithmarsha\", \"thrivechiropracticstudio\", \"thrivechiropracticstudio\", \"thrivechiropracticstudio\", \"time\", \"time\", \"time\", \"timely\", \"timely\", \"timely\", \"timely\", \"tip\", \"tip\", \"today\", \"today\", \"today\", \"today\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"treatyourself\", \"treatyourself\", \"treatyourself\", \"u\", \"u\", \"u\", \"va\", \"va\", \"va\", \"vegan\", \"vegan\", \"vegan\", \"visitdurango\", \"visitdurango\", \"visitdurango\", \"vitamin\", \"vitamin\", \"vitamin\", \"warriortwopose\", \"warriortwopose\", \"warriortwopose\", \"watch\", \"watch\", \"watch\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"weight\", \"weight\", \"weight\", \"weightloss\", \"weightloss\", \"weightloss\", \"weightloss\", \"well\", \"well\", \"well\", \"wellness\", \"wellness\", \"wellness\", \"wellness\", \"wellnessmatters\", \"wellnessmatters\", \"wellnessmatters\", \"wellnessmatters\", \"without\", \"without\", \"without\", \"work\", \"work\", \"work\", \"yall\", \"yall\", \"year\", \"year\", \"year\", \"yoga\", \"yoga\", \"yoga\", \"yoga.denisse\", \"yoga.denisse\", \"yoga.denisse\", \"yogasequence\", \"yogasequence\", \"yogasequence\", \"youmatter\", \"youmatter\", \"youmatter\", \"youmatter\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [6, 4, 5, 7, 1, 3, 2, 8]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1711396578480356644559357520\", ldavis_el1711396578480356644559357520_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1711396578480356644559357520\", ldavis_el1711396578480356644559357520_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1711396578480356644559357520\", ldavis_el1711396578480356644559357520_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "5     -0.201964 -0.130128       1        1  35.829701\n",
              "3     -0.175512  0.144181       2        1  34.741415\n",
              "4      0.060756  0.033390       3        1  11.147132\n",
              "6      0.063862 -0.008458       4        1   5.670083\n",
              "0      0.066061 -0.009190       5        1   3.981883\n",
              "2      0.060871 -0.011238       6        1   3.174799\n",
              "1      0.059835 -0.008528       7        1   2.921385\n",
              "7      0.066092 -0.010030       8        1   2.533602, topic_info=               Term         Freq        Total Category  logprob  loglift\n",
              "20             care  3379.000000  3379.000000  Default  30.0000  30.0000\n",
              "3              self  3109.000000  3109.000000  Default  29.0000  29.0000\n",
              "13        self-care  1620.000000  1620.000000  Default  28.0000  28.0000\n",
              "4          selfcare  1884.000000  1884.000000  Default  27.0000  27.0000\n",
              "127             day   964.000000   964.000000  Default  26.0000  26.0000\n",
              "...             ...          ...          ...      ...      ...      ...\n",
              "15985            va     2.283899     8.083996   Topic8  -7.2791   2.4115\n",
              "5491     staystrong     1.807161     6.112619   Topic8  -7.5133   2.4569\n",
              "15837      handbook     5.250679    35.709914   Topic8  -6.4467   1.7585\n",
              "6317   psychologist     1.736868     7.800203   Topic8  -7.5529   2.1735\n",
              "3314         phrase     1.771893    11.067746   Topic8  -7.5330   1.8435\n",
              "\n",
              "[382 rows x 6 columns], token_table=       Topic      Freq                                               Term\n",
              "term                                                                     \n",
              "16151      1  0.192806  .\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\n",
              "16151      2  0.192806  .\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\n",
              "16151      8  0.385612  .\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\\n.\n",
              "768        1  0.952835                                                 ..\n",
              "768        2  0.015124                                                 ..\n",
              "...      ...       ...                                                ...\n",
              "16159      8  0.385612                                       yogasequence\n",
              "2314       1  0.031295                                          youmatter\n",
              "2314       2  0.031295                                          youmatter\n",
              "2314       3  0.813682                                          youmatter\n",
              "2314       7  0.062591                                          youmatter\n",
              "\n",
              "[1111 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[6, 4, 5, 7, 1, 3, 2, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibl5UFyV-5TW"
      },
      "source": [
        "So how to infer pyLDAvis’s output?\n",
        "\n",
        "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
        "\n",
        "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
        "\n",
        "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
        "\n",
        "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8URnYhM6fFSQ"
      },
      "source": [
        "## Finding the dominant topic in each sentence\n",
        "\n",
        "One of the practical application of topic modeling is to determine what topic a given document is about.\n",
        "\n",
        "To find that, we find the topic number that has the highest percentage contribution in that document.\n",
        "\n",
        "The format_topics_sentences() function below nicely aggregates this information in a presentable table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lbnWQeChXq0B",
        "outputId": "33a1cc40-f7b5-41ce-d31e-51019fbd9c73"
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=df['Text']):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document_No</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7050</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>SelfCare is the BESTCare❗️💯, put yo self first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.4147</td>\n",
              "      <td>self-care, selfcare, time, help, health, take,...</td>\n",
              "      <td>Breaking workaholic thought patterns takes mor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7890</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>Self Care is a must ..... Tarot Reading is hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.6335</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>Self love and self care. Invest in yourself.  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7070</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>So excited for self  care Friday tomorrow!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.4659</td>\n",
              "      <td>self-care, selfcare, time, help, health, take,...</td>\n",
              "      <td>Download EBOOK Saturday Night Pasta: Recipes a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.8578</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>Happy Luna Full Moon in Leo everyone! Remember...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.7006</td>\n",
              "      <td>self-care, selfcare, time, help, health, take,...</td>\n",
              "      <td>Swipe.Match.Heal\\nDownload #GinaApp https://t....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.8054</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>Love the feature on my phone that automaticall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7956</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>decided to treat myself and buy the bfish guid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Document_No  ...                                               Text\n",
              "0            0  ...  SelfCare is the BESTCare❗️💯, put yo self first...\n",
              "1            1  ...  Breaking workaholic thought patterns takes mor...\n",
              "2            2  ...  Self Care is a must ..... Tarot Reading is hap...\n",
              "3            3  ...  Self love and self care. Invest in yourself.  ...\n",
              "4            4  ...         So excited for self  care Friday tomorrow!\n",
              "5            5  ...  Download EBOOK Saturday Night Pasta: Recipes a...\n",
              "6            6  ...  Happy Luna Full Moon in Leo everyone! Remember...\n",
              "7            7  ...  Swipe.Match.Heal\\nDownload #GinaApp https://t....\n",
              "8            8  ...  Love the feature on my phone that automaticall...\n",
              "9            9  ...  decided to treat myself and buy the bfish guid...\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-TIwQZPhUVS"
      },
      "source": [
        "## Topic distribution across documents\n",
        "\n",
        "Finally, we want to understand the volume and distribution of topics in order to judge how widely it was discussed. The below grahic exposes that information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWf9BH-2vtg3"
      },
      "source": [
        "df_merge = pd.merge(df, df_dominant_topic, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fzkCQwsoito8",
        "outputId": "95d2d463-234e-4d37-97df-95b7ef772fb5"
      },
      "source": [
        "df_merge.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Text_x</th>\n",
              "      <th>text_lemmatized</th>\n",
              "      <th>Document_No</th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Topic_Perc_Contrib</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Text_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2021-01-18</td>\n",
              "      <td>SelfCare is the BESTCare❗️💯, put yo self first...</td>\n",
              "      <td>[selfcare, bestcare, put, yo, self, first]</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7050</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>SelfCare is the BESTCare❗️💯, put yo self first...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2021-01-21</td>\n",
              "      <td>Breaking workaholic thought patterns takes mor...</td>\n",
              "      <td>[break, workaholic, thought, pattern, take, mi...</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.4147</td>\n",
              "      <td>self-care, selfcare, time, help, health, take,...</td>\n",
              "      <td>Breaking workaholic thought patterns takes mor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2021-01-26</td>\n",
              "      <td>Self Care is a must ..... Tarot Reading is hap...</td>\n",
              "      <td>[self, care, must, ..., tarot, reading, happen...</td>\n",
              "      <td>2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7890</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>Self Care is a must ..... Tarot Reading is hap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2021-01-19</td>\n",
              "      <td>Self love and self care. Invest in yourself.  ...</td>\n",
              "      <td>[self, love, self, care, invest, madewithripl,...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.6335</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>Self love and self care. Invest in yourself.  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2021-01-24</td>\n",
              "      <td>So excited for self  care Friday tomorrow!</td>\n",
              "      <td>[excite, self, care, friday, tomorrow]</td>\n",
              "      <td>4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.7070</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "      <td>So excited for self  care Friday tomorrow!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Row_id  ...                                             Text_y\n",
              "0       1  ...  SelfCare is the BESTCare❗️💯, put yo self first...\n",
              "1       2  ...  Breaking workaholic thought patterns takes mor...\n",
              "2       3  ...  Self Care is a must ..... Tarot Reading is hap...\n",
              "3       4  ...  Self love and self care. Invest in yourself.  ...\n",
              "4       5  ...         So excited for self  care Friday tomorrow!\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l1MVYZtjq_a",
        "outputId": "0ce0fd9f-4700-4068-fbbf-894fc755ef81"
      },
      "source": [
        "#all topics\n",
        "df_merge['Keywords'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['care, self, day, today, get, ..., take, like, im, go',\n",
              "       'self-care, selfcare, time, help, health, take, practice, new, tip, stress',\n",
              "       'selfcare, selflove, love, therapy, bliss, motivation, heal, mentalhealth, inspiration, soul',\n",
              "       'book, massage, appointment, doctor, spaday, blackownedbusiness, recommendation, spa, salon, reschedule',\n",
              "       'skincare, beauty, skin, selfcare, product, fitness, beautiful, natural, tea, vitamin',\n",
              "       'make, sure, saturday, priority, could, selfcaresunday, lovely, storm, selfish, selfnurture',\n",
              "       'divorce, fall, theyre, clarity, youmatter, reputationintelligence, mediation, mirror, eliminatebullying, reflexology',\n",
              "       'harmony, akafit, mylifestyle, 6miles, payattentiontothehiddengems, enjoythescenery, pastorlife, stoprushingeverywhere, allyouhaveistime, justdoit'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "4KcH3QP4ktVy",
        "outputId": "01fe130c-ffc2-4cca-a0cd-0a7e7686e47a"
      },
      "source": [
        "# All topics and number of topic\n",
        "df_merge[['Dominant_Topic', 'Keywords']].drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dominant_Topic</th>\n",
              "      <th>Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>care, self, day, today, get, ..., take, like, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.0</td>\n",
              "      <td>self-care, selfcare, time, help, health, take,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>4.0</td>\n",
              "      <td>selfcare, selflove, love, therapy, bliss, moti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>2.0</td>\n",
              "      <td>book, massage, appointment, doctor, spaday, bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>6.0</td>\n",
              "      <td>skincare, beauty, skin, selfcare, product, fit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>0.0</td>\n",
              "      <td>make, sure, saturday, priority, could, selfcar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>1.0</td>\n",
              "      <td>divorce, fall, theyre, clarity, youmatter, rep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>7.0</td>\n",
              "      <td>harmony, akafit, mylifestyle, 6miles, payatten...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Dominant_Topic                                           Keywords\n",
              "0               5.0  care, self, day, today, get, ..., take, like, ...\n",
              "1               3.0  self-care, selfcare, time, help, health, take,...\n",
              "18              4.0  selfcare, selflove, love, therapy, bliss, moti...\n",
              "65              2.0  book, massage, appointment, doctor, spaday, bl...\n",
              "92              6.0  skincare, beauty, skin, selfcare, product, fit...\n",
              "177             0.0  make, sure, saturday, priority, could, selfcar...\n",
              "188             1.0  divorce, fall, theyre, clarity, youmatter, rep...\n",
              "249             7.0  harmony, akafit, mylifestyle, 6miles, payatten..."
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMpN354kk9v7"
      },
      "source": [
        "df_timeseries = df_merge[['Date', 'Dominant_Topic', 'Document_No']].groupby(['Date', 'Dominant_Topic']).count().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlWWHv47ly-5",
        "outputId": "8e96e536-c79a-49d0-c8e4-3845f450fac8"
      },
      "source": [
        "df_timeseries.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 165 entries, 0 to 164\n",
            "Data columns (total 3 columns):\n",
            " #   Column          Non-Null Count  Dtype         \n",
            "---  ------          --------------  -----         \n",
            " 0   Date            165 non-null    datetime64[ns]\n",
            " 1   Dominant_Topic  165 non-null    float64       \n",
            " 2   Document_No     165 non-null    int64         \n",
            "dtypes: datetime64[ns](1), float64(1), int64(1)\n",
            "memory usage: 4.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "3XwhJDO0l9uW",
        "outputId": "9cb8aacc-5a3a-455f-c326-6bf63f6e6de7"
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.line(df_timeseries, x=\"Date\", y='Document_No', color='Dominant_Topic',\n",
        "              title='Topic over time')\n",
        "fig.update_xaxes(\n",
        "    tickformat=\"%Y-%m-%d\"\n",
        "    )\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"bb4ba31a-9776-465f-bd13-b208e27137aa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"bb4ba31a-9776-465f-bd13-b208e27137aa\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'bb4ba31a-9776-465f-bd13-b208e27137aa',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=0.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=0.0\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=0.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [15, 6, 8, 5, 9, 6, 7, 9, 11, 9, 5, 5, 6, 7, 6, 4, 8, 3, 9, 10, 7], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=1.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=1.0\", \"line\": {\"color\": \"#EF553B\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=1.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [6, 4, 2, 3, 5, 3, 2, 3, 5, 2, 8, 1, 5, 1, 6, 4, 4, 4, 4, 4], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=2.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=2.0\", \"line\": {\"color\": \"#00cc96\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=2.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [7, 3, 5, 2, 2, 6, 5, 4, 3, 6, 4, 4, 1, 7, 5, 2, 6, 4, 1, 3], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=3.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=3.0\", \"line\": {\"color\": \"#ab63fa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=3.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [173, 185, 156, 147, 160, 156, 172, 158, 177, 173, 174, 164, 161, 158, 176, 165, 183, 160, 141, 175, 150], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=4.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=4.0\", \"line\": {\"color\": \"#FFA15A\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=4.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [41, 43, 40, 39, 54, 40, 31, 47, 45, 62, 45, 50, 40, 48, 44, 43, 49, 36, 52, 44, 35], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=5.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=5.0\", \"line\": {\"color\": \"#19d3f3\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=5.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [242, 239, 234, 244, 251, 227, 240, 199, 228, 224, 231, 242, 229, 253, 233, 240, 235, 220, 209, 214, 236], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=6.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=6.0\", \"line\": {\"color\": \"#FF6692\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=6.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [13, 12, 17, 11, 11, 12, 13, 9, 16, 11, 17, 11, 21, 10, 20, 15, 14, 8, 20, 15, 11], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Dominant_Topic=7.0<br>Date=%{x}<br>Document_No=%{y}\", \"legendgroup\": \"Dominant_Topic=7.0\", \"line\": {\"color\": \"#B6E880\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"Dominant_Topic=7.0\", \"showlegend\": true, \"type\": \"scatter\", \"x\": [\"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\"], \"xaxis\": \"x\", \"y\": [4, 6, 1, 4, 4, 1, 3, 2, 1, 4, 4, 3, 3, 3, 1, 2, 3, 2, 2, 2], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Topic over time\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"tickformat\": \"%Y-%m-%d\", \"title\": {\"text\": \"Date\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Document_No\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bb4ba31a-9776-465f-bd13-b208e27137aa');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}