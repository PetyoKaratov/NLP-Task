{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "topic_modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSg9e8Pmr52Ae/QFm72PiX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PetyoKaratov/NLP-Task/blob/main/topic_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcqZIop_mT0V"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds3xMGbzQoGi",
        "outputId": "cfb2c8e8-1138-49be-81e0-bd59de956c90"
      },
      "source": [
        "!pip install openpyxl==3.0.0\n",
        "!pip install emot\n",
        "!pip install pyldavis"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openpyxl==3.0.0\n",
            "  Downloading openpyxl-3.0.0.tar.gz (172 kB)\n",
            "\u001b[K     |████████████████████████████████| 172 kB 7.3 MB/s \n",
            "\u001b[?25hCollecting jdcal\n",
            "  Downloading jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: et_xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl==3.0.0) (1.1.0)\n",
            "Building wheels for collected packages: openpyxl\n",
            "  Building wheel for openpyxl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openpyxl: filename=openpyxl-3.0.0-py2.py3-none-any.whl size=241207 sha256=cee0a3ab9fb1514e4a17487798915ab9cdbde72622785f80d168eb3654fd5ec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/64/ff/ce98f6e1d2701ae8e216c875da62feed2839ac8a3cae0ab8af\n",
            "Successfully built openpyxl\n",
            "Installing collected packages: jdcal, openpyxl\n",
            "  Attempting uninstall: openpyxl\n",
            "    Found existing installation: openpyxl 3.0.10\n",
            "    Uninstalling openpyxl-3.0.10:\n",
            "      Successfully uninstalled openpyxl-3.0.10\n",
            "Successfully installed jdcal-1.4.1 openpyxl-3.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emot\n",
            "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 23 kB/s \n",
            "\u001b[?25hInstalling collected packages: emot\n",
            "Successfully installed emot-3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyldavis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 8.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.0.2)\n",
            "Collecting funcy\n",
            "  Downloading funcy-1.17-py2.py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyldavis) (3.6.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.8.3)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.7.3)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyldavis) (2.11.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyldavis) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyldavis) (57.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyldavis) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyldavis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyldavis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyldavis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyldavis) (2.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyldavis) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyldavis) (3.0.9)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->pyldavis) (3.1.0)\n",
            "Building wheels for collected packages: pyldavis, sklearn\n",
            "  Building wheel for pyldavis (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyldavis: filename=pyLDAvis-3.3.1-py2.py3-none-any.whl size=136898 sha256=d610d0bcaf24ea009997b5ace2054ddd19a98b7ce1293695fdd23cea82f7a203\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/21/f6/17bcf2667e8a68532ba2fbf6d5c72fdf4c7f7d9abfa4852d2f\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=25a3a7e617ebc50a68f627253a912c46cd5e1ef00a028f43b1759b1218942e5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
            "Successfully built pyldavis sklearn\n",
            "Installing collected packages: sklearn, funcy, pyldavis\n",
            "Successfully installed funcy-1.17 pyldavis-3.3.1 sklearn-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iItP_86pxDX",
        "outputId": "bc002f22-e1ad-4560-8470-8240461dea34"
      },
      "source": [
        "# imports\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import re                                  # library for regular expression operations\n",
        "import string                              # for string operations\n",
        "import pprint\n",
        "import nltk \n",
        "import numpy as np\n",
        "import tqdm\n",
        "import emot \n",
        "# download the stopwords from NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
        "from nltk.stem import WordNetLemmatizer    # module for lemmatization\n",
        "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Plotting tools\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models  \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyF44PFWp91X",
        "outputId": "fb5cff5a-9a93-4478-c815-68809eedb2a2"
      },
      "source": [
        "# mount the google drive root\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uJUg8VQqljN",
        "outputId": "401c331f-a18b-4142-d4de-0b1b91bc4d98"
      },
      "source": [
        "# read the excel file\n",
        "df = pd.read_excel('./drive/My Drive/NLP_Task_Data.xlsx')\n",
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 56255 entries, 0 to 56254\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   Row_id  9915 non-null   float64       \n",
            " 1   Date    9915 non-null   datetime64[ns]\n",
            " 2   Text    56255 non-null  object        \n",
            "dtypes: datetime64[ns](1), float64(1), object(1)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sj0-AEUHxXYO",
        "outputId": "ec8af213-1340-454f-b04b-29d7a51a0106"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Row_id       Date                                               Text\n",
              "0     1.0 2021-01-18  is upset that he can't update his Facebook by ...\n",
              "1     2.0 2021-01-21  @Kenichan I dived many times for the ball. Man...\n",
              "2     3.0 2021-01-26     my whole body feels itchy and like its on fire\n",
              "3     4.0 2021-01-19  @nationwideclass no, it's not behaving at all....\n",
              "4     5.0 2021-01-24                       @Kwesidei not the whole crew"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9e8eed90-c3ee-423d-9adf-967aca0aa41b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-01-18</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2021-01-21</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2021-01-26</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2021-01-19</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2021-01-24</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e8eed90-c3ee-423d-9adf-967aca0aa41b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e8eed90-c3ee-423d-9adf-967aca0aa41b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e8eed90-c3ee-423d-9adf-967aca0aa41b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4AkKDhnJxSmb",
        "outputId": "016801da-c795-44d1-ae7d-42bdb4b0bde7"
      },
      "source": [
        "tweet = df.Text[1]\n",
        "tweet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHTVMPiDxiSR"
      },
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_5Qxbx6IquG"
      },
      "source": [
        "To preprocess the tweet we remove stock market tickers, old stype retweet text, hashtafs tokenize the weets with TweetTokenizer and then remove stopwords punctuation and lemmatizing. Lemmatisation (or lemmatization) in linguistics is the process of grouping together the inflected forms of a word so they can be analysed as a single item, identified by the word's lemma, or dictionary form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWmX6KV9v-kZ",
        "outputId": "a76b86b4-a929-4907-ec89-05374c0a7ec8"
      },
      "source": [
        "def process_tweet(tweet: str) -> str:\n",
        "    \"\"\"Process tweet function.\n",
        "    Input:\n",
        "        tweet: a string containing a tweet\n",
        "    Output:\n",
        "        tweets_clean: a list of words containing the processed tweet\n",
        "    \"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stopwords_english = stopwords.words('english')\n",
        "    # remove stock market tickers like $GE\n",
        "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
        "    # remove old style retweet text \"RT\"\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    # remove hyperlinks\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "    # remove hashtags\n",
        "    # only removing the hash # sign from the word\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    # remove emoticons\n",
        "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)\n",
        "    # tokenize tweets\n",
        "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "    tweets_clean = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and  # remove stopwords\n",
        "                word not in string.punctuation): # remove punctuation\n",
        "            lemmatize_word = lemmatizer.lemmatize(word, get_wordnet_pos(word))  # lemmatizing word\n",
        "            tweets_clean.append(lemmatize_word)\n",
        "\n",
        "    return tweets_clean\n",
        "\n",
        "# choose the same tweet\n",
        "tweet = df.Text[0]\n",
        "\n",
        "print()\n",
        "print('\\033[92m')\n",
        "print(tweet)\n",
        "print('\\033[94m')\n",
        "\n",
        "# call the imported function\n",
        "tweets_stem = process_tweet(tweet); # Preprocess a given tweet\n",
        "\n",
        "print('preprocessed tweet:')\n",
        "print(tweets_stem) # Print the result"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[92m\n",
            "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
            "\u001b[94m\n",
            "preprocessed tweet:\n",
            "['upset', \"can't\", 'update', 'facebook', 'texting', '...', 'might', 'cry', 'result', 'school', 'today', 'also', 'blah']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m14-y6pdLDcH"
      },
      "source": [
        "Apply tweet preprocessing to all tweets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bBByru13nul"
      },
      "source": [
        "df['text_lemmatized'] = df['Text'].apply(process_tweet)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Oy7ch1ui39yd",
        "outputId": "6d1f5e52-3993-4c03-8db5-6af7370be683"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Row_id       Date                                               Text  \\\n",
              "0     1.0 2021-01-18  is upset that he can't update his Facebook by ...   \n",
              "1     2.0 2021-01-21  @Kenichan I dived many times for the ball. Man...   \n",
              "2     3.0 2021-01-26     my whole body feels itchy and like its on fire   \n",
              "3     4.0 2021-01-19  @nationwideclass no, it's not behaving at all....   \n",
              "4     5.0 2021-01-24                       @Kwesidei not the whole crew   \n",
              "\n",
              "                                     text_lemmatized  \n",
              "0  [upset, can't, update, facebook, texting, ...,...  \n",
              "1  [dive, many, time, ball, manage, save, 50, res...  \n",
              "2             [whole, body, feel, itchy, like, fire]  \n",
              "3                   [behaving, i'm, mad, can't, see]  \n",
              "4                                      [whole, crew]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d1fc3b2-5865-47ec-9887-91d5ae0ac667\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Row_id</th>\n",
              "      <th>Date</th>\n",
              "      <th>Text</th>\n",
              "      <th>text_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-01-18</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>[upset, can't, update, facebook, texting, ...,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2021-01-21</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>[dive, many, time, ball, manage, save, 50, res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2021-01-26</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>[whole, body, feel, itchy, like, fire]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2021-01-19</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>[behaving, i'm, mad, can't, see]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2021-01-24</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "      <td>[whole, crew]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d1fc3b2-5865-47ec-9887-91d5ae0ac667')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d1fc3b2-5865-47ec-9887-91d5ae0ac667 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d1fc3b2-5865-47ec-9887-91d5ae0ac667');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z64ghnsyLbC4"
      },
      "source": [
        "Create the Dictionary and Corpus needed for Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyAAVn5G4fxc",
        "outputId": "41fb36e9-8849-4520-a4d5-9175b6f343c0"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(df['text_lemmatized'])\n",
        "\n",
        "# Create Corpus\n",
        "texts = df['text_lemmatized']\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UscGUrYgLj74"
      },
      "source": [
        "Gensim creates a unique id for each word in the document. The produced corpus shown above is a mapping of (word_id, word_frequency).\n",
        "\n",
        "For example, (0, 1) above implies, word id 0 occurs once in the first document. Likewise, word id 1 occurs twice and so on.\n",
        "\n",
        "This is used as the input by the LDA model.\n",
        "\n",
        "If you want to see what word a given id corresponds to, pass the id as a key to the dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZicJvxg04o-J",
        "outputId": "7123ad53-ff8e-4156-ac35-dd3f536d2355"
      },
      "source": [
        "id2word[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbtwxScyLuJZ",
        "outputId": "6a92d0cb-a9e4-45b8-971e-3ea41f4d4fbe"
      },
      "source": [
        "# Human readable format of corpus (term-frequency)\n",
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('...', 1),\n",
              "  ('also', 1),\n",
              "  ('blah', 1),\n",
              "  (\"can't\", 1),\n",
              "  ('cry', 1),\n",
              "  ('facebook', 1),\n",
              "  ('might', 1),\n",
              "  ('result', 1),\n",
              "  ('school', 1),\n",
              "  ('texting', 1),\n",
              "  ('today', 1),\n",
              "  ('update', 1),\n",
              "  ('upset', 1)]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qsbt3Z2MI0v"
      },
      "source": [
        "### Base Model\n",
        "\n",
        "We have everything required to train the base Latent Dirichlet Allocation (LDA) model. In addition to the corpus and dictionary, you need to provide the number of topics as well. Apart from that, alpha and eta are hyperparameters that affect sparsity of the topics. According to the Gensim docs, both defaults to 1.0/num_topics prior (we’ll use default for the base model).\n",
        "\n",
        "    chunksize controls how many documents are processed at a time in the training algorithm. Increasing chunksize will speed up training, at least as long as the chunk of documents easily fit into memory.\n",
        "\n",
        "    passes controls how often we train the model on the entire corpus (set to 10). Another word for passes might be “epochs”. iterations is somewhat technical, but essentially it controls how often we repeat a particular loop over each document. It is important to set the number of “passes” and “iterations” high enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf1dHtp3MSum"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                       id2word=id2word,\n",
        "                                       num_topics=10, \n",
        "                                       random_state=100,\n",
        "                                       chunksize=100,\n",
        "                                       passes=10,\n",
        "                                       per_word_topics=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OJPPL3lNGxq"
      },
      "source": [
        "### View the topics in LDA model\n",
        "\n",
        "The above LDA model is built with 20 different topics where each topic is a combination of keywords and each keyword contributes a certain weightage to the topic.\n",
        "\n",
        "You can see the keywords for each topic and the weightage(importance) of each keyword using lda_model.print_topics() as shown next."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paYUaOqzNQR7",
        "outputId": "fdca4e03-4016-437e-a708-792be236bc35"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint.pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.059*\"work\" + 0.055*\"...\" + 0.055*\"go\" + 0.047*\"get\" + 0.043*\"day\" + '\n",
            "  '0.033*\"wish\" + 0.029*\"back\" + 0.026*\"home\" + 0.026*\"i\\'m\" + 0.024*\"want\"'),\n",
            " (1,\n",
            "  '0.052*\"sad\" + 0.038*\"watch\" + 0.026*\"look\" + 0.025*\"hurt\" + 0.025*\"...\" + '\n",
            "  '0.022*\"lose\" + 0.019*\"man\" + 0.018*\"make\" + 0.016*\"i\\'m\" + 0.014*\"die\"'),\n",
            " (2,\n",
            "  '0.042*\"night\" + 0.033*\"last\" + 0.032*\"...\" + 0.018*\"bore\" + 0.017*\"movie\" + '\n",
            "  '0.016*\"time\" + 0.016*\"saturday\" + 0.015*\"start\" + 0.014*\"party\" + '\n",
            "  '0.014*\"left\"'),\n",
            " (3,\n",
            "  '0.087*\"..\" + 0.044*\"im\" + 0.028*\"think\" + 0.025*\"take\" + 0.020*\"miss\" + '\n",
            "  '0.019*\"come\" + 0.018*\"wanna\" + 0.018*\"gonna\" + 0.018*\"dont\" + 0.016*\"want\"'),\n",
            " (4,\n",
            "  '0.047*\"miss\" + 0.042*\"...\" + 0.042*\"u\" + 0.036*\"i\\'m\" + 0.032*\"really\" + '\n",
            "  '0.032*\"sorry\" + 0.026*\"lol\" + 0.018*\"twitter\" + 0.016*\"hate\" + 0.016*\"go\"'),\n",
            " (5,\n",
            "  '0.038*\"tonight\" + 0.027*\"new\" + 0.024*\"try\" + 0.020*\"phone\" + '\n",
            "  '0.017*\"already\" + 0.016*\"house\" + 0.012*\"i\\'ve\" + 0.012*\"seem\" + '\n",
            "  '0.012*\"song\" + 0.011*\"forgot\"'),\n",
            " (6,\n",
            "  '0.020*\"leave\" + 0.020*\"thing\" + 0.018*\"that\\'s\" + 0.018*\"give\" + '\n",
            "  '0.017*\"another\" + 0.015*\"let\" + 0.015*\"omg\" + 0.012*\"stupid\" + 0.012*\"5\" + '\n",
            "  '0.011*\"drive\"'),\n",
            " (7,\n",
            "  '0.045*\"can\\'t\" + 0.028*\"see\" + 0.025*\"say\" + 0.023*\"week\" + 0.023*\"though\" '\n",
            "  '+ 0.022*\"suck\" + 0.021*\"get\" + 0.019*\"would\" + 0.019*\"even\" + '\n",
            "  '0.018*\"weekend\"'),\n",
            " (8,\n",
            "  '0.061*\"like\" + 0.048*\"feel\" + 0.036*\"...\" + 0.031*\"know\" + 0.027*\"make\" + '\n",
            "  '0.024*\"bad\" + 0.024*\"well\" + 0.019*\"one\" + 0.019*\"rain\" + 0.019*\"get\"'),\n",
            " (9,\n",
            "  '0.049*\"need\" + 0.039*\"much\" + 0.029*\"...\" + 0.029*\"right\" + 0.019*\"i\\'m\" + '\n",
            "  '0.019*\"way\" + 0.018*\"ugh\" + 0.017*\"fun\" + 0.017*\"life\" + 0.015*\"think\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcJz1cJPOpJc"
      },
      "source": [
        "### Compute Model Perplexity and Coherence Score\n",
        "\n",
        "Model perplexity and topic coherence provide a convenient measure to judge how good a given topic model is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON82K4qJOK-X",
        "outputId": "5b45bd4e-7555-4d24-9246-4022ac97310f"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['text_lemmatized'], dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity:  -9.00950600941515\n",
            "\n",
            "Coherence Score:  0.2602388475736583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjCCrKGh2tD"
      },
      "source": [
        "### Hyperparameter Tuning\n",
        "\n",
        "First, let’s differentiate between model hyperparameters and model parameters :\n",
        "\n",
        "    Model hyperparameters can be thought of as settings for a machine learning algorithm that are tuned by the data scientist before training. Examples would be the number of trees in the random forest, or in our case, number of topics K\n",
        "\n",
        "    Model parameters can be thought of as what the model learns during training, such as the weights for each word in a given topic\n",
        "\n",
        "Now that we have the baseline coherence score for the default LDA model, let’s perform a series of sensitivity tests to help determine the following model hyperparameters:\n",
        "\n",
        "    Number of Topics (K)\n",
        "    Dirichlet hyperparameter alpha: Document-Topic Density\n",
        "    Dirichlet hyperparameter beta: Word-Topic Density\n",
        "\n",
        "We’ll perform these tests in sequence, one parameter at a time by keeping others constant. We’ll use C_v as our choice of metric for performance comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCzEqRcYh42f"
      },
      "source": [
        "# supporting function\n",
        "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
        "    \n",
        "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=dictionary,\n",
        "                                           num_topics=k, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=a,\n",
        "                                           eta=b)\n",
        "    \n",
        "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df['text_lemmatized'], dictionary=id2word, coherence='c_v')\n",
        "    \n",
        "    return coherence_model_lda.get_coherence()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwUWXSLZiJv0"
      },
      "source": [
        "Let’s call the function, and iterate it over the range of topics, alpha, and beta parameter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wkgVh-l_4mh",
        "outputId": "91245b04-fa8b-43a4-f225-0b978e1e18af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "grid = {}\n",
        "grid['Validation_Set'] = {}# Topics range\n",
        "min_topics = 2\n",
        "max_topics = 11\n",
        "step_size = 1\n",
        "topics_range = range(min_topics, max_topics, step_size)# Alpha parameter\n",
        "alpha = list(np.arange(0.01, 1, 0.3))\n",
        "alpha.append('symmetric')\n",
        "alpha.append('asymmetric')# Beta parameter\n",
        "beta = list(np.arange(0.01, 1, 0.3))\n",
        "beta.append('symmetric')# Validation sets\n",
        "num_of_docs = len(corpus)\n",
        "corpus_sets = [\n",
        "               corpus]\n",
        "corpus_title = ['100% Corpus']\n",
        "model_results = {'Validation_Set': [],\n",
        "                 'Topics': [],\n",
        "                 'Alpha': [],\n",
        "                 'Beta': [],\n",
        "                 'Coherence': []\n",
        "                }# Can take a long time to run\n",
        "\n",
        "pbar = tqdm.tqdm(total=50)\n",
        "\n",
        "# iterate through validation corpuses\n",
        "for i in range(len(corpus_sets)):\n",
        "    # iterate through number of topics\n",
        "    for k in topics_range:\n",
        "        # iterate through alpha values\n",
        "        for a in alpha:\n",
        "            # iterare through beta values\n",
        "            for b in beta:\n",
        "                # get the coherence score for the given parameters\n",
        "                cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, k=int(k), a=a, b=b)\n",
        "                # Save the model results\n",
        "                model_results['Validation_Set'].append(corpus_title[i])\n",
        "                model_results['Topics'].append(k)\n",
        "                model_results['Alpha'].append(a)\n",
        "                model_results['Beta'].append(b)\n",
        "                model_results['Coherence'].append(cv)\n",
        "                \n",
        "                pbar.update(1)\n",
        "pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
        "pbar.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1023: RuntimeWarning: divide by zero encountered in log\n",
            "  diff = np.log(self.expElogbeta)\n",
            "74it [6:19:56, 300.81s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uui3QWjE-t_p"
      },
      "source": [
        "## Final Model\n",
        "\n",
        "Let’s train the final model using the above selected parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgoxfHyBdvAg"
      },
      "source": [
        "model_df = pd.read_csv('./drive/My Drive/lda_tuning_results.csv')\n",
        "model_df.sort_values(by=['Coherence']).tail(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx9QpU0GBDES"
      },
      "source": [
        "The best model is with 5 topis but I select the one with 8 to work with more topics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MTqMbn1vsD0"
      },
      "source": [
        "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=8, \n",
        "                                           random_state=100,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha=0.31,\n",
        "                                           eta=0.90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxfkG_87-mV_"
      },
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "LDAvis_prepared = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
        "LDAvis_prepared"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibl5UFyV-5TW"
      },
      "source": [
        "So how to infer pyLDAvis’s output?\n",
        "\n",
        "Each bubble on the left-hand side plot represents a topic. The larger the bubble, the more prevalent is that topic.\n",
        "\n",
        "A good topic model will have fairly big, non-overlapping bubbles scattered throughout the chart instead of being clustered in one quadrant.\n",
        "\n",
        "A model with too many topics, will typically have many overlaps, small sized bubbles clustered in one region of the chart.\n",
        "\n",
        "Alright, if you move the cursor over one of the bubbles, the words and bars on the right-hand side will update. These words are the salient keywords that form the selected topic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8URnYhM6fFSQ"
      },
      "source": [
        "## Finding the dominant topic in each sentence\n",
        "\n",
        "One of the practical application of topic modeling is to determine what topic a given document is about.\n",
        "\n",
        "To find that, we find the topic number that has the highest percentage contribution in that document.\n",
        "\n",
        "The format_topics_sentences() function below nicely aggregates this information in a presentable table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbnWQeChXq0B"
      },
      "source": [
        "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=df['Text']):\n",
        "    # Init output\n",
        "    sent_topics_df = pd.DataFrame()\n",
        "\n",
        "    # Get main topic in each document\n",
        "    for i, row in enumerate(ldamodel[corpus]):\n",
        "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
        "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
        "        for j, (topic_num, prop_topic) in enumerate(row):\n",
        "            if j == 0:  # => dominant topic\n",
        "                wp = ldamodel.show_topic(topic_num)\n",
        "                topic_keywords = \", \".join([word for word, prop in wp])\n",
        "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
        "            else:\n",
        "                break\n",
        "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
        "\n",
        "    # Add original text to the end of the output\n",
        "    contents = pd.Series(texts)\n",
        "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
        "    return(sent_topics_df)\n",
        "\n",
        "\n",
        "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus)\n",
        "\n",
        "# Format\n",
        "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
        "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
        "\n",
        "# Show\n",
        "df_dominant_topic.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-TIwQZPhUVS"
      },
      "source": [
        "## Topic distribution across documents\n",
        "\n",
        "Finally, we want to understand the volume and distribution of topics in order to judge how widely it was discussed. The below grahic exposes that information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWf9BH-2vtg3"
      },
      "source": [
        "df_merge = pd.merge(df, df_dominant_topic, left_index=True, right_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzkCQwsoito8"
      },
      "source": [
        "df_merge.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8l1MVYZtjq_a"
      },
      "source": [
        "#all topics\n",
        "df_merge['Keywords'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KcH3QP4ktVy"
      },
      "source": [
        "# All topics and number of topic\n",
        "df_merge[['Dominant_Topic', 'Keywords']].drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMpN354kk9v7"
      },
      "source": [
        "df_timeseries = df_merge[['Date', 'Dominant_Topic', 'Document_No']].groupby(['Date', 'Dominant_Topic']).count().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlWWHv47ly-5"
      },
      "source": [
        "df_timeseries.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XwhJDO0l9uW"
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.line(df_timeseries, x=\"Date\", y='Document_No', color='Dominant_Topic',\n",
        "              title='Topic over time')\n",
        "fig.update_xaxes(\n",
        "    tickformat=\"%Y-%m-%d\"\n",
        "    )\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}